{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11684907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "from util import *\n",
    "from framepool import *\n",
    "# Importing utility functions from the original code\n",
    "# Assuming these functions are defined in your util.py module\n",
    "# from util import recover_seq, rev_rna_vocab, encode_seq_framepool, one_hot_all_motif\n",
    "# from framepool import load_framepool\n",
    "\n",
    "# For demonstration, we'll add placeholder functions since we don't have the actual util.py\n",
    "def reverse_complement(sequence):\n",
    "    \"\"\"Compute the reverse complement of a DNA sequence.\"\"\"\n",
    "    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C', \n",
    "                  'a': 't', 't': 'a', 'c': 'g', 'g': 'c', 'N': 'N', 'n': 'N'}\n",
    "    return ''.join(complement.get(base, 'N') for base in reversed(sequence))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reverse_complement(sequence):\n",
    "    \"\"\"Compute the reverse complement of a DNA sequence.\"\"\"\n",
    "    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C', \n",
    "                  'a': 't', 't': 'a', 'c': 'g', 'g': 'c', 'N': 'N', 'n': 'N'}\n",
    "    return ''.join(complement.get(base, 'N') for base in reversed(sequence))\n",
    "\n",
    "def one_hot(seq):\n",
    "    \"\"\"Convert sequences to one-hot encoding.\"\"\"\n",
    "    convert = True\n",
    "    if isinstance(seq, tf.Tensor):\n",
    "        seq = seq.numpy().astype(str)\n",
    "        convert = True\n",
    "\n",
    "    num_seqs = len(seq)\n",
    "    seq_len = len(seq[0])\n",
    "    seqindex = {'A':0, 'C':1, 'G':2, 'T':3, 'a':0, 'c':1, 'g':2, 't':3}\n",
    "    seq_vec = np.zeros((num_seqs, seq_len, 4), dtype='bool')\n",
    "    for i in range(num_seqs):\n",
    "        thisseq = seq[i]\n",
    "        for j in range(seq_len):\n",
    "            try:\n",
    "                seq_vec[i, j, seqindex[thisseq[j]]] = 1\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    if convert:\n",
    "        seq_vec = tf.convert_to_tensor(seq_vec, dtype=tf.float32)\n",
    "\n",
    "    return seq_vec\n",
    "\n",
    "class GeneInfoRetriever:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://rest.ensembl.org\"\n",
    "        self.headers = {\"Content-Type\": \"application/json\"}\n",
    "        self.sleep_time = 0.5  # Respect Ensembl API rate limits\n",
    "        \n",
    "        # Create cache directory if it doesn't exist\n",
    "        os.makedirs('./.cache/', exist_ok=True)\n",
    "        os.makedirs('./outputs/', exist_ok=True)\n",
    "\n",
    "    def _make_request(self, endpoint):\n",
    "        \"\"\"Make a request to the Ensembl REST API.\"\"\"\n",
    "        url = self.base_url + endpoint\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            time.sleep(self.sleep_time)\n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                print(f\"Error: {response.status_code} - {response.text}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Request error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_gene_id(self, gene_symbol, species=\"homo_sapiens\"):\n",
    "        \"\"\"Retrieve the Ensembl gene ID for a gene symbol.\"\"\"\n",
    "        endpoint = f\"/lookup/symbol/{species}/{gene_symbol}\"\n",
    "        response = self._make_request(endpoint)\n",
    "        return response.get(\"id\") if response else None\n",
    "\n",
    "    def get_gene_coordinates(self, gene_id):\n",
    "        \"\"\"Retrieve genomic coordinates for a gene ID.\"\"\"\n",
    "        endpoint = f\"/lookup/id/{gene_id}?expand=1\"\n",
    "        response = self._make_request(endpoint)\n",
    "        if response:\n",
    "            return {\n",
    "                \"chromosome\": response.get(\"seq_region_name\"),\n",
    "                \"start\": response.get(\"start\"),\n",
    "                \"end\": response.get(\"end\"),\n",
    "                \"strand\": response.get(\"strand\")\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    def get_tss_and_utr(self, gene_id):\n",
    "        \"\"\"Retrieve TSS and 5' UTR coordinates for the canonical transcript.\"\"\"\n",
    "        endpoint = f\"/lookup/id/{gene_id}?expand=1&utr=1\"\n",
    "        response = self._make_request(endpoint)\n",
    "        if not response or \"Transcript\" not in response:\n",
    "            return None\n",
    "\n",
    "        # Find canonical transcript\n",
    "        canonical_transcript = None\n",
    "        for transcript in response[\"Transcript\"]:\n",
    "            if transcript.get(\"is_canonical\", 0) == 1:\n",
    "                canonical_transcript = transcript\n",
    "                break\n",
    "        if not canonical_transcript:\n",
    "            for transcript in response[\"Transcript\"]:\n",
    "                if transcript.get(\"biotype\") == \"protein_coding\":\n",
    "                    canonical_transcript = transcript\n",
    "                    break\n",
    "        if not canonical_transcript:\n",
    "            canonical_transcript = response[\"Transcript\"][0] if response[\"Transcript\"] else None\n",
    "\n",
    "        if not canonical_transcript:\n",
    "            return None\n",
    "\n",
    "        # Determine TSS and 5' UTR\n",
    "        strand = canonical_transcript.get(\"strand\")\n",
    "        tss = canonical_transcript[\"start\"] if strand == 1 else canonical_transcript[\"end\"]\n",
    "        five_prime_utr = None\n",
    "\n",
    "        if \"UTR\" in canonical_transcript:\n",
    "            for utr in canonical_transcript[\"UTR\"]:\n",
    "                if utr.get(\"object_type\") == \"five_prime_UTR\":\n",
    "                    five_prime_utr = {\n",
    "                        \"start\": utr.get(\"start\"),\n",
    "                        \"end\": utr.get(\"end\")\n",
    "                    }\n",
    "                    break\n",
    "\n",
    "        # Verify TSS matches 5' UTR start\n",
    "        if five_prime_utr:\n",
    "            expected_tss = five_prime_utr[\"start\"] if strand == 1 else five_prime_utr[\"end\"]\n",
    "            if expected_tss != tss:\n",
    "                print(f\"Warning: Adjusting TSS from {tss} to match 5' UTR {'start' if strand == 1 else 'end'} ({expected_tss})\")\n",
    "                tss = expected_tss\n",
    "\n",
    "        return {\n",
    "            \"tss\": tss,\n",
    "            \"strand\": strand,\n",
    "            \"chromosome\": canonical_transcript.get(\"seq_region_name\"),\n",
    "            \"five_prime_utr\": five_prime_utr,\n",
    "            \"transcript_id\": canonical_transcript.get(\"id\")\n",
    "        }\n",
    "\n",
    "    def get_promoter_sequence(self, gene_id, upstream=8000, downstream=4000):\n",
    "        \"\"\"Retrieve sequence around TSS (8kb upstream, 4kb downstream).\"\"\"\n",
    "        tss_info = self.get_tss_and_utr(gene_id)\n",
    "        if not tss_info:\n",
    "            return None, None\n",
    "\n",
    "        chromosome = tss_info[\"chromosome\"]\n",
    "        strand = tss_info[\"strand\"]\n",
    "        tss_position = tss_info[\"tss\"]\n",
    "\n",
    "        # Calculate region based on strand\n",
    "        if strand == 1:\n",
    "            seq_start = tss_position - upstream\n",
    "            seq_end = tss_position + downstream - 1\n",
    "        else:\n",
    "            seq_start = tss_position - downstream\n",
    "            seq_end = tss_position + upstream - 1\n",
    "\n",
    "        seq_start = max(1, seq_start)\n",
    "\n",
    "        # Store sequence coordinates\n",
    "        sequence_coords = {\n",
    "            \"chromosome\": chromosome,\n",
    "            \"start\": seq_start,\n",
    "            \"end\": seq_end,\n",
    "            \"strand\": 1 if strand == 1 else -1\n",
    "        }\n",
    "\n",
    "        # Validate 5' UTR inclusion\n",
    "        if tss_info[\"five_prime_utr\"]:\n",
    "            utr_start = tss_info[\"five_prime_utr\"][\"start\"]\n",
    "            utr_end = tss_info[\"five_prime_utr\"][\"end\"]\n",
    "            if not (seq_start <= utr_start <= seq_end and seq_start <= utr_end <= seq_end):\n",
    "                print(f\"Warning: 5' UTR ({utr_start}-{utr_end}) not fully within sequence ({seq_start}-{seq_end})\")\n",
    "\n",
    "        # Get sequence\n",
    "        strand_str = \"1\" if strand == 1 else \"-1\"\n",
    "        endpoint = f\"/sequence/region/human/{chromosome}:{seq_start}..{seq_end}:{strand_str}\"\n",
    "        response = self._make_request(endpoint)\n",
    "        return response.get(\"seq\") if response else None, sequence_coords\n",
    "\n",
    "    def get_gene_info(self, gene_symbol, species=\"homo_sapiens\", output_json=\"gene_info.json\"):\n",
    "        \"\"\"Retrieve and save promoter sequence, TSS, 5' UTR, and coordinates.\"\"\"\n",
    "        cache_file = os.path.join('./.cache/', f\"{gene_symbol}_info.json\")\n",
    "        \n",
    "        if not os.path.exists(cache_file):\n",
    "            # Get gene ID\n",
    "            gene_id = self.get_gene_id(gene_symbol, species)\n",
    "            if not gene_id:\n",
    "                return {\"error\": f\"Gene {gene_symbol} not found\"}\n",
    "\n",
    "            # Get TSS and 5' UTR\n",
    "            tss_info = self.get_tss_and_utr(gene_id)\n",
    "            if not tss_info:\n",
    "                return {\"error\": \"Could not retrieve TSS or transcript information\"}\n",
    "\n",
    "            # Get promoter sequence and coordinates\n",
    "            promoter_sequence, sequence_coords = self.get_promoter_sequence(gene_id)\n",
    "            if not promoter_sequence:\n",
    "                return {\"error\": \"Could not retrieve promoter sequence\"}\n",
    "\n",
    "            # Compile gene information\n",
    "            gene_info = {\n",
    "                \"gene_symbol\": gene_symbol,\n",
    "                \"gene_id\": gene_id,\n",
    "                \"promoter_sequence\": promoter_sequence,\n",
    "                \"sequence_length\": len(promoter_sequence),\n",
    "                \"sequence_coordinates\": sequence_coords,\n",
    "                \"tss\": {\n",
    "                    \"chromosome\": tss_info[\"chromosome\"],\n",
    "                    \"position\": tss_info[\"tss\"],\n",
    "                    \"strand\": \"+\" if tss_info[\"strand\"] == 1 else \"-\"\n",
    "                },\n",
    "                \"five_prime_utr\": tss_info[\"five_prime_utr\"],\n",
    "                \"transcript_id\": tss_info[\"transcript_id\"]\n",
    "            }\n",
    "\n",
    "            # Save to JSON\n",
    "            try:\n",
    "                with open(cache_file, \"w\") as f:\n",
    "                    json.dump(gene_info, f, indent=2)\n",
    "                print(f\"Saved gene information to {cache_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving JSON: {e}\")\n",
    "        else:\n",
    "            with open(cache_file, \"r\") as f:\n",
    "                gene_info = json.load(f)\n",
    "\n",
    "        return gene_info\n",
    "\n",
    "    def replace_utr_in_sequence(self, gene_info_file, generated_utrs, target_length=10500, output_prefix=\"modified_sequence\", write_json=False, verbose=False):\n",
    "        \"\"\"\n",
    "        Replace original 5' UTR with generated UTRs, ensuring target_length output.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Read gene information\n",
    "            with open(gene_info_file, \"r\") as f:\n",
    "                gene_info = json.load(f)\n",
    "\n",
    "            original_sequence = gene_info[\"promoter_sequence\"]\n",
    "            strand = gene_info[\"tss\"][\"strand\"]\n",
    "            tss_position = gene_info[\"tss\"][\"position\"]\n",
    "            sequence_coords = gene_info[\"sequence_coordinates\"]\n",
    "            seq_start = sequence_coords[\"start\"]\n",
    "            seq_end = sequence_coords[\"end\"]\n",
    "            five_prime_utr = gene_info[\"five_prime_utr\"]\n",
    "            gene_symbol = gene_info[\"gene_symbol\"]\n",
    "            transcript_id = gene_info[\"transcript_id\"]\n",
    "\n",
    "            if not five_prime_utr:\n",
    "                print(f\"Error: No 5' UTR information available for {gene_symbol}\")\n",
    "                return []\n",
    "\n",
    "            # Calculate original 5' UTR position in sequence\n",
    "            if strand == \"+\":\n",
    "                utr_start_genomic = five_prime_utr[\"start\"]\n",
    "                utr_end_genomic = five_prime_utr[\"end\"]\n",
    "                utr_start_seq = utr_start_genomic - seq_start\n",
    "                utr_end_seq = utr_end_genomic - seq_start\n",
    "            else:\n",
    "                utr_start_genomic = five_prime_utr[\"end\"]  # TSS\n",
    "                utr_end_genomic = five_prime_utr[\"start\"]\n",
    "                utr_start_seq = seq_end - utr_start_genomic\n",
    "                utr_end_seq = seq_end - utr_end_genomic\n",
    "\n",
    "            # Validate UTR positions\n",
    "            seq_length = len(original_sequence)\n",
    "            if not (0 <= utr_start_seq <= seq_length and 0 <= utr_end_seq <= seq_length):\n",
    "                print(f\"Error: 5' UTR coordinates (seq indices {utr_start_seq}-{utr_end_seq}) out of sequence bounds (0-{seq_length}) for {gene_symbol}\")\n",
    "                return []\n",
    "\n",
    "            original_utr_length = abs(utr_end_genomic - utr_start_genomic) + 1\n",
    "            if verbose:\n",
    "                print(f\"Original 5' UTR length for {gene_symbol}: {original_utr_length} nt\")\n",
    "\n",
    "            modified_sequences = []\n",
    "            for i, new_utr in enumerate(generated_utrs):\n",
    "                new_utr_length = len(new_utr)\n",
    "                if not 64 <= new_utr_length <= 128:\n",
    "                    if verbose:\n",
    "                        print(f\"Warning: Generated UTR {i+1} length ({new_utr_length}) outside 64-128nt range for {gene_symbol}\")\n",
    "                    continue\n",
    "\n",
    "                # Construct new sequence\n",
    "                if strand == \"+\":\n",
    "                    new_sequence = (\n",
    "                        original_sequence[:utr_start_seq] +\n",
    "                        new_utr +\n",
    "                        original_sequence[utr_end_seq + 1:]\n",
    "                    )\n",
    "                    new_utr_start_genomic = utr_start_genomic\n",
    "                    new_utr_end_genomic = utr_start_genomic + new_utr_length - 1\n",
    "                    if len(new_sequence) > target_length:\n",
    "                        new_sequence = new_sequence[:target_length]\n",
    "                        sequence_coords[\"end\"] = seq_start + target_length - 1\n",
    "                    elif len(new_sequence) < target_length:\n",
    "                        if verbose:\n",
    "                            print(f\"Error: Sequence too short ({len(new_sequence)} nt) after UTR replacement for {gene_symbol}\")\n",
    "                        continue\n",
    "                else:\n",
    "                    new_utr_rc = reverse_complement(new_utr)\n",
    "                    new_sequence = (\n",
    "                        original_sequence[:min(utr_start_seq, utr_end_seq)] +\n",
    "                        new_utr_rc +\n",
    "                        original_sequence[max(utr_start_seq, utr_end_seq) + 1:]\n",
    "                    )\n",
    "                    new_utr_start_genomic = utr_start_genomic\n",
    "                    new_utr_end_genomic = utr_start_genomic - new_utr_length + 1\n",
    "                    if len(new_sequence) > target_length:\n",
    "                        trim_amount = len(new_sequence) - target_length\n",
    "                        new_sequence = new_sequence[trim_amount:]\n",
    "                        sequence_coords[\"start\"] = seq_start + trim_amount\n",
    "                    elif len(new_sequence) < target_length:\n",
    "                        if verbose:\n",
    "                            print(f\"Error: Sequence too short ({len(new_sequence)} nt) after UTR replacement for {gene_symbol}\")\n",
    "                        continue\n",
    "\n",
    "                # Store modified sequence and metadata\n",
    "                modified_info = {\n",
    "                    \"gene_symbol\": gene_symbol,\n",
    "                    \"transcript_id\": transcript_id,\n",
    "                    \"modified_sequence\": new_sequence,\n",
    "                    \"sequence_length\": len(new_sequence),\n",
    "                    \"sequence_coordinates\": sequence_coords.copy(),\n",
    "                    \"tss\": gene_info[\"tss\"],\n",
    "                    \"five_prime_utr\": {\n",
    "                        \"start\": new_utr_start_genomic,\n",
    "                        \"end\": new_utr_end_genomic,\n",
    "                        \"sequence\": new_utr if strand == \"+\" else new_utr_rc\n",
    "                    },\n",
    "                    \"original_utr_length\": original_utr_length,\n",
    "                    \"new_utr_length\": new_utr_length,\n",
    "                    \"utr_index\": i + 1\n",
    "                }\n",
    "\n",
    "                # Save to JSON\n",
    "                if write_json:\n",
    "                    output_file = f\"{output_prefix}_{gene_symbol}_utr_{i+1}.json\"\n",
    "                    try:\n",
    "                        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "                        with open(output_file, \"w\") as f:\n",
    "                            json.dump(modified_info, f, indent=2)\n",
    "                        print(f\"Saved modified sequence {i+1} for {gene_symbol} to {output_file}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error saving modified sequence {i+1} for {gene_symbol}: {e}\")\n",
    "\n",
    "                modified_sequences.append(modified_info[\"modified_sequence\"])\n",
    "\n",
    "            return modified_sequences\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing UTR replacement for {gene_info.get('gene_symbol', 'unknown')}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def replace_utr_in_multiple_sequences(self, gene_symbols, generated_utrs, target_length=10500, cache_dir=\"./.cache\", output_prefix=\"modified_sequence\", verbose=False):\n",
    "        \"\"\"\n",
    "        Replace 5' UTRs for multiple genes with generated UTRs.\n",
    "        \"\"\"\n",
    "        all_modified_sequences = []\n",
    "        n_utrs = len(generated_utrs)\n",
    "        n_genes = len(gene_symbols)\n",
    "\n",
    "        for gene_symbol in gene_symbols:\n",
    "            json_file = os.path.join(cache_dir, f\"{gene_symbol}_info.json\")\n",
    "            if not os.path.exists(json_file):\n",
    "                print(f\"Error: Gene info file {json_file} not found\")\n",
    "                continue\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\nProcessing gene: {gene_symbol}\")\n",
    "            modified_sequences = self.replace_utr_in_sequence(\n",
    "                gene_info_file=json_file,\n",
    "                generated_utrs=generated_utrs,\n",
    "                target_length=target_length,\n",
    "                output_prefix=os.path.join(cache_dir, output_prefix)\n",
    "            )\n",
    "\n",
    "            if modified_sequences:\n",
    "                all_modified_sequences.extend(modified_sequences)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"No modified sequences generated for {gene_symbol}\")\n",
    "\n",
    "        expected_count = n_utrs * n_genes\n",
    "        actual_count = len(all_modified_sequences)\n",
    "        if verbose:\n",
    "            print(f\"\\nGenerated {actual_count} modified sequences (expected: {expected_count})\")\n",
    "\n",
    "        return all_modified_sequences\n",
    "\n",
    "def convert_model(model_):\n",
    "    # print(model_.summary())\n",
    "    input_ = tf.keras.layers.Input(shape=( 10500, 4))\n",
    "    input = input_\n",
    "    for i in range(len(model_.layers)-1):\n",
    "\n",
    "        # print(type(model_.layers[i+1]))\n",
    "        \n",
    "        if isinstance(model_.layers[i+1],tf.keras.layers.Concatenate):\n",
    "            paddings = tf.constant([[0,0],[0,6]])\n",
    "            output = tf.pad(input, paddings, 'CONSTANT')\n",
    "            input = output\n",
    "        else:\n",
    "            if not isinstance(model_.layers[i+1],tf.keras.layers.InputLayer):\n",
    "                output = model_.layers[i+1](input)\n",
    "                input = output\n",
    "\n",
    "            if isinstance(model_.layers[i+1],tf.keras.layers.Conv1D):\n",
    "                pass\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_, outputs=output)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    return model\n",
    "\n",
    "def select_best(scores, seqs, gc_control=False, GC=-1):\n",
    "    \"\"\"Select best sequences based on scores.\"\"\"\n",
    "    selected_scores = []\n",
    "    selected_seqs = []\n",
    "    for i in range(len(scores[0])):\n",
    "        best = scores[1][i]\n",
    "        best_seq = seqs[1][i]\n",
    "        for j in range(len(scores)-1):\n",
    "            if scores[j+1][i] > best:\n",
    "                best = scores[j+1][i]\n",
    "                best_seq = seqs[j+1][i]\n",
    "\n",
    "        selected_scores.append(best)\n",
    "        selected_seqs.append(best_seq)\n",
    "\n",
    "    return selected_seqs, selected_scores\n",
    "\n",
    "def select_best_per_gene(scores, seqs, gc_control=False, GC=-1):\n",
    "    \"\"\"Select best sequences based on scores along the other axis.\"\"\"\n",
    "    \"\"\"Select best sequences based on scores.\"\"\"\n",
    "    selected_scores = []\n",
    "    selected_seqs = []\n",
    "    for i in range(len(scores[0])):\n",
    "        best = np.mean(scores[1][i])\n",
    "        best_seq = seqs[1][i]\n",
    "        for j in range(len(scores)-1):\n",
    "            if np.mean(scores[j+1][i]) > best:\n",
    "                best = np.mean(scores[j+1][i])\n",
    "                best_seq = seqs[j+1][i]\n",
    "\n",
    "        selected_scores.append(best)\n",
    "        selected_seqs.append(best_seq)\n",
    "\n",
    "    return selected_seqs, selected_scores\n",
    "\n",
    "def optimize_gene_set(initial_genes, target_genes, batch_size=100, steps=50, lr=0.001, verbose=False):\n",
    "    \"\"\"Optimize 5' UTR sequences for a set of genes and evaluate on target genes.\"\"\"\n",
    "    # Constants and model paths\n",
    "    UTR_LEN = 128\n",
    "    DIM = 40\n",
    "    N_GENES = 8\n",
    "    BATCH_SIZE = batch_size\n",
    "    STEPS = steps\n",
    "\n",
    "    SEQ_BATCH = N_GENES\n",
    "    UTR_LEN = 128\n",
    "    DIM = 40\n",
    "    LR = lr  # Convert to the exponential format used in the original code\n",
    "    gpath = './../../models/checkpoint_3000.h5'  # GAN model\n",
    "    exp_path = './../../models/humanMedian_trainepoch.11-0.426.h5'  # Expression model\n",
    "    mrl_path = './../../models/utr_model_combined_residual_new.h5'  # MRL model\n",
    "\n",
    "    # Set device for TensorFlow\n",
    "    if torch.cuda.is_available():\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    \n",
    "    model = tf.keras.models.load_model(exp_path)\n",
    "\n",
    "    model = convert_model(model)\n",
    "\n",
    "    wgan = tf.keras.models.load_model(gpath)\n",
    "\n",
    "    \"\"\"\n",
    "    Data:\n",
    "    \"\"\"\n",
    "\n",
    "    gene_names = [\"MYOC\", \"TIGD4\", \"ATP6V1B2\", \"TAGLN\", \"COX7A2L\", \"IFNGR2\", \"TNFRSF21\", \"SETD6\"]\n",
    "\n",
    "    noise = tf.Variable(tf.random.normal(shape=[BATCH_SIZE,40]))\n",
    "\n",
    "    tf.random.set_seed(25)\n",
    "\n",
    "    diffs = []\n",
    "    init_exps = []\n",
    "\n",
    "    opt_exps = []\n",
    "\n",
    "    orig_vals = []\n",
    "\n",
    "    noise = tf.Variable(tf.random.normal(shape=[BATCH_SIZE,40]))\n",
    "    noise_small = tf.random.normal(shape=[BATCH_SIZE,40],stddev=1e-5)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "\n",
    "    '''\n",
    "    Optimization takes place here.\n",
    "    '''\n",
    "\n",
    "    bind_scores_list = []\n",
    "    bind_scores_means = []\n",
    "    sequences_list = []\n",
    "\n",
    "    means = []\n",
    "    maxes = []\n",
    "\n",
    "    iters_ = []\n",
    "\n",
    "    OPTIMIZE = True\n",
    "\n",
    "    DNA_SEL = False\n",
    "\n",
    "    retriever = GeneInfoRetriever()\n",
    "    refs = []\n",
    "    for i in range(len(gene_names)):\n",
    "        output_json = f\"{gene_names[i]}_info.json\"\n",
    "\n",
    "        if not os.path.exists(os.path.join('./.cache/',output_json)):\n",
    "\n",
    "            # Retrieve gene information\n",
    "            gene_info = retriever.get_gene_info(gene_names[i], output_json=output_json)\n",
    "\n",
    "            if \"error\" in gene_info:\n",
    "                print(f\"Error: {gene_info['error']}\")\n",
    "            else:\n",
    "                refs.append(gene_info[\"promoter_sequence\"])    \n",
    "        else:\n",
    "            with open(os.path.join('./.cache/',output_json), \"r\") as f:\n",
    "                gene_info = json.load(f)\n",
    "                refs.append(gene_info[\"promoter_sequence\"])\n",
    "\n",
    "    sequences_init = wgan(noise)\n",
    "\n",
    "    gen_seqs_init = sequences_init.numpy().astype('float')\n",
    "\n",
    "    seqs_gen_init = recover_seq(gen_seqs_init, rev_rna_vocab)\n",
    "\n",
    "    seqs_init = retriever.replace_utr_in_multiple_sequences(gene_names, seqs_gen_init, target_length=10500, cache_dir=\"./.cache\", output_prefix=\"modified_sequence\")\n",
    "\n",
    "    tf.shape(seqs_init)\n",
    "\n",
    "    seqs_init = one_hot(seqs_init)\n",
    "\n",
    "    pred_init = model(seqs_init) \n",
    "\n",
    "    pred_init = tf.reshape(pred_init,(SEQ_BATCH,-1))\n",
    "\n",
    "    initial_exp_per_gene = tf.reduce_mean(pred_init,axis=1)\n",
    "\n",
    "    init_t = tf.reduce_mean(pred_init,axis=0)\n",
    "\n",
    "    init_t = init_t.numpy().astype('float')\n",
    "\n",
    "\n",
    "    ########### MRL and TE check before optimization ###################\n",
    "\n",
    "    # seqs_mrl = tf.convert_to_tensor(np.array([encode_seq_framepool(seq) for seq in seqs_gen_init]),dtype=tf.float32)\n",
    "    # seqs_te =  torch.transpose(torch.tensor(np.array(one_hot_all_motif(seqs_gen_init),dtype=np.float32)),2,1).float().to(device)\n",
    "\n",
    "    # mrl_preds_init = mrl_model(seqs_mrl).numpy().astype('float')\n",
    "    # te_preds_init = te_model.forward(seqs_te).cpu().data.numpy()\n",
    "\n",
    "    ####################################################################\n",
    "\n",
    "    STEPS = STEPS\n",
    "\n",
    "    seqs_collection = []\n",
    "    seqs_collection_genes = []\n",
    "    scores_collection = []\n",
    "    scores_collection_genes = []\n",
    "    if OPTIMIZE:\n",
    "\n",
    "        \n",
    "        iter_ = 0\n",
    "        for opt_iter in tqdm(range(STEPS)):\n",
    "            \n",
    "            with tf.GradientTape() as gtape:\n",
    "                gtape.watch(noise)\n",
    "                \n",
    "                sequences = wgan(noise)\n",
    "\n",
    "                seqs_gen = recover_seq(sequences, rev_rna_vocab)\n",
    "                seqs_collection.append(seqs_gen)\n",
    "\n",
    "                g1_ = tf.zeros_like(sequences)\n",
    "\n",
    "                scores_collection_temp = []\n",
    "                means_temp = []\n",
    "                maxes_temp = []\n",
    "\n",
    "\n",
    "                for gene in gene_names:\n",
    "\n",
    "                    seqs_dna = retriever.replace_utr_in_sequence(f\"./.cache/{gene}_info.json\", seqs_gen, target_length=10500, output_prefix=\"modified_sequence\")               \n",
    "                \n",
    "                    seqs = one_hot(seqs_dna)\n",
    "                    \n",
    "                    with tf.GradientTape() as ptape:\n",
    "                        ptape.watch(seqs)\n",
    "\n",
    "                        pred =  model(seqs)\n",
    "                        t = tf.reshape(pred,(-1))\n",
    "                        mx = np.amax(t.numpy().astype('float'),axis=0)\n",
    "                        mx = np.max(mx)\n",
    "                        \n",
    "\n",
    "                        scores_collection_temp.append(t.numpy().astype('float'))\n",
    "                        nt = t.numpy().astype('float')\n",
    "                        maxes_temp.append(mx)\n",
    "                        means_temp.append(np.sum(t)/BATCH_SIZE)\n",
    "\n",
    "                    g1 = ptape.gradient(pred,seqs)\n",
    "                    g1 = tf.math.scalar_mul(-1.0, g1)\n",
    "                    g1 = tf.slice(g1,[0,7000,0],[-1,128,-1])\n",
    "\n",
    "                    tmp_g = g1.numpy().astype('float')\n",
    "                    tmp_seqs = seqs_gen\n",
    "\n",
    "                    # # Before the loop\n",
    "                    # print(\"Length of tmp_seqs:\", len(tmp_seqs))\n",
    "                    # print(\"Shape of tmp_g:\", tmp_g.shape)\n",
    "\n",
    "                    # Initialize tmp_lst with correct size\n",
    "                    batch_size = min(len(tmp_seqs), tmp_g.shape[0])\n",
    "                    tmp_lst = np.zeros(shape=(batch_size, 128, 5))\n",
    "\n",
    "                    # Loop with safe range\n",
    "                    for i in range(batch_size):\n",
    "                        len_ = min(len(tmp_seqs[i]), tmp_g.shape[1])  # Prevent exceeding tmp_g's dimensions\n",
    "                        edited_g = tmp_g[i][:len_, :]\n",
    "                        edited_g = np.pad(edited_g, ((0, 128-len_), (0, 1)), 'constant')\n",
    "                        tmp_lst[i] = edited_g\n",
    "\n",
    "                    g1 = tf.convert_to_tensor(tmp_lst, dtype=tf.float32)\n",
    "\n",
    "                    g1_ = tf.math.add(g1, g1_)\n",
    "\n",
    "                scores_collection.append(np.mean(scores_collection_temp,axis=0))\n",
    "                scores_collection_genes.append(scores_collection_temp)\n",
    "                means.append(np.mean(means_temp))\n",
    "                maxes.append(np.max(maxes_temp))\n",
    "\n",
    "                g2 = gtape.gradient(sequences,noise,output_gradients=g1_)\n",
    "\n",
    "\n",
    "            a1 = g2 + noise_small\n",
    "            change = [(a1,noise)]\n",
    "\n",
    "            optimizer.apply_gradients(change)\n",
    "\n",
    "            iters_.append(iter_)\n",
    "            iter_ += 1\n",
    "\n",
    "        sequences_opt = wgan(noise)\n",
    "\n",
    "        gen_seqs_opt = sequences_opt.numpy().astype('float')\n",
    "\n",
    "        seqs_gen_opt = recover_seq(gen_seqs_opt, rev_rna_vocab)\n",
    "\n",
    "        seqs_opt = retriever.replace_utr_in_multiple_sequences(gene_names, seqs_gen_opt, target_length=10500, cache_dir=\"./.cache\", output_prefix=\"modified_sequence\")\n",
    "\n",
    "        seqs_opt = one_hot(seqs_opt)\n",
    "\n",
    "        pred_opt = model(seqs_opt)\n",
    "\n",
    "        pred_opt = tf.reshape(pred_opt,(SEQ_BATCH,-1))\n",
    "\n",
    "\n",
    "        t = tf.reduce_mean(pred_opt,axis=0)\n",
    "        opt_t = t.numpy().astype('float')\n",
    "\n",
    "    ########### MRL and TE check after optimization ####################\n",
    "\n",
    "    # seqs_mrl = tf.convert_to_tensor(np.array([encode_seq_framepool(seq) for seq in seqs_gen_opt]),dtype=tf.float32)\n",
    "    # seqs_te =  torch.transpose(torch.tensor(np.array(one_hot_all_motif(seqs_gen_opt),dtype=np.float32)),2,1).float().to(device)\n",
    "\n",
    "    # mrl_preds_opt = mrl_model(seqs_mrl).numpy().astype('float')\n",
    "    # te_preds_opt = te_model.forward(seqs_te).cpu().data.numpy()\n",
    "\n",
    "    ####################################################################\n",
    "\n",
    "    best_seqs, best_scores = select_best(scores_collection, seqs_collection)\n",
    "    _, best_scores_per_gene = select_best_per_gene(scores_collection_genes, seqs_collection)\n",
    "\n",
    "    with open('./outputs/mul_init_exps.txt', 'w') as f:\n",
    "        for item in init_t:\n",
    "            f.write(f'{item}\\n')\n",
    "\n",
    "    with open('./outputs/mul_best_exps.txt', 'w') as f:\n",
    "        for item in best_scores:\n",
    "            f.write(f'{item}\\n')\n",
    "\n",
    "    with open('./outputs/mul_opt_exps.txt', 'w') as f:\n",
    "        for item in opt_t:\n",
    "            f.write(f'{item}\\n')\n",
    "\n",
    "    with open('./outputs/mul_best_seqs.txt', 'w') as f:\n",
    "        for item in best_seqs:\n",
    "            f.write(f'{item}\\n')\n",
    "\n",
    "    with open('./outputs/mul_init_seqs.txt', 'w') as f:\n",
    "        for item in seqs_gen_init:\n",
    "            f.write(f'{item}\\n')\n",
    "\n",
    "    # Compute average Log TPM per gene\n",
    "    init_log_tpm_initial = tf.reduce_mean(pred_init, axis=1).numpy().astype('float')\n",
    "    opt_log_tpm_initial = tf.reduce_mean(pred_opt, axis=1).numpy().astype('float')\n",
    "    opt_log_tpm_initial = best_scores\n",
    "\n",
    "    # Compute overall average Log TPM across target genes\n",
    "    avg_init_log_tpm_initial = np.average(init_log_tpm_initial)\n",
    "    avg_opt_log_tpm_initial = np.average(opt_log_tpm_initial)\n",
    "\n",
    "    # Convert Log TPM to TPM for percentage improvement\n",
    "    # Assuming Log TPM is base-10 (common for TPM), TPM = 10^LogTPM\n",
    "    avg_init_tpm_initial = np.power(10, avg_init_log_tpm_initial)\n",
    "    avg_opt_tpm_initial = np.power(10, avg_opt_log_tpm_initial)\n",
    "\n",
    "    # Compute improvement\n",
    "    log_tpm_diff_initial = avg_opt_log_tpm_initial - avg_init_log_tpm_initial\n",
    "    tpm_improvement_initial = avg_opt_tpm_initial - avg_init_tpm_initial\n",
    "    # Percentage improvement based on TPM: ((opt - init) / init) * 100\n",
    "    if avg_init_tpm_initial != 0:  # Avoid division by zero\n",
    "        tpm_percent_change_initial = (tpm_improvement_initial / avg_init_tpm_initial) * 100\n",
    "    else:\n",
    "        tpm_percent_change_initial = float('inf') if tpm_improvement_initial > 0 else 0.0\n",
    "\n",
    "    # Handle negative and positive percentages\n",
    "    percent_str = f\"{tpm_percent_change_initial:.2f}%\"\n",
    "    if tpm_percent_change_initial < 0:\n",
    "        percent_str = f\"{tpm_percent_change_initial:.2f}% (decrease)\"\n",
    "    elif tpm_percent_change_initial > 0:\n",
    "        percent_str = f\"+{tpm_percent_change_initial:.2f}% (increase)\"\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(\"\\nEvaluation of Optimization on Original Genes (Log TPM):\")\n",
    "    print(\"\\nExpression Levels (Log TPM):\")\n",
    "    print(f\"  Average Initial Log TPM: {avg_init_log_tpm_initial:.4f} (TPM: {avg_init_tpm_initial:.4f})\")\n",
    "    print(f\"  Average Optimized Log TPM: {avg_opt_log_tpm_initial:.4f} (TPM: {avg_opt_tpm_initial:.4f})\")\n",
    "    print(f\"  Log TPM Difference: {log_tpm_diff_initial:.4f}\")\n",
    "    print(f\"  TPM Improvement: {tpm_improvement_initial:.4f} ({percent_str})\")\n",
    "\n",
    "\n",
    "    print(\"Genes:\")\n",
    "    print(gene_names)\n",
    "    print(f\"Average Initial Expression: {np.average(init_t)}\")\n",
    "    print(f\"Best Expression: {np.average(best_scores)}\")\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"#TODO Evaluate Optimization on Target Genes \"\"\"\n",
    "\n",
    "    # Define a new list of target genes\n",
    "    target_genes = [\"ANTXR2\", \"NFIL3\", \"UNC13D\", \"DHRS2\", \"RPS13\", \"HBD\", \"METAP1D\", \"NCALD\"]\n",
    "\n",
    "    # Initialize the retriever for gene information\n",
    "    retriever = GeneInfoRetriever()\n",
    "\n",
    "    # Retrieve promoter sequences for target genes\n",
    "    target_refs = []\n",
    "    for gene in target_genes:\n",
    "        output_json = f\"{gene}_info.json\"\n",
    "        cache_path = os.path.join('./.cache/', output_json)\n",
    "        \n",
    "        if not os.path.exists(cache_path):\n",
    "            # Retrieve gene information\n",
    "            gene_info = retriever.get_gene_info(gene, output_json=output_json)\n",
    "            if \"error\" in gene_info:\n",
    "                print(f\"Error retrieving info for {gene}: {gene_info['error']}\")\n",
    "                target_refs.append(None)  # Handle errors gracefully\n",
    "            else:\n",
    "                target_refs.append(gene_info[\"promoter_sequence\"])\n",
    "        else:\n",
    "            with open(cache_path, \"r\") as f:\n",
    "                gene_info = json.load(f)\n",
    "                target_refs.append(gene_info[\"promoter_sequence\"])\n",
    "\n",
    "    # Filter out any None entries (failed retrievals)\n",
    "    valid_indices = [i for i, ref in enumerate(target_refs) if ref is not None]\n",
    "    target_genes = [target_genes[i] for i in valid_indices]\n",
    "    target_refs = [target_refs[i] for i in valid_indices]\n",
    "\n",
    "    if not target_genes:\n",
    "        print(\"No valid target genes retrieved. Exiting evaluation.\")\n",
    "    else:\n",
    "        # Use initial and optimized sequences from the original optimization\n",
    "        seqs_gen_init = seqs_gen_init  # From original gene optimization\n",
    "        seqs_gen_opt = best_seqs    # From original gene optimization\n",
    "\n",
    "        # Replace UTRs in target genes' promoter sequences with initial and optimized sequences\n",
    "        seqs_init_target = retriever.replace_utr_in_multiple_sequences(\n",
    "            target_genes, seqs_gen_init, target_length=10500, cache_dir=\"./.cache\", output_prefix=\"target_modified_sequence\"\n",
    "        )\n",
    "        seqs_opt_target = retriever.replace_utr_in_multiple_sequences(\n",
    "            target_genes, seqs_gen_opt, target_length=10500, cache_dir=\"./.cache\", output_prefix=\"target_modified_sequence\"\n",
    "        )\n",
    "\n",
    "        # One-hot encode the sequences\n",
    "        seqs_init_target = one_hot(seqs_init_target)\n",
    "        seqs_opt_target = one_hot(seqs_opt_target)\n",
    "\n",
    "        # Predict expression levels (Log TPM) using the model\n",
    "        pred_init_target = model(seqs_init_target)\n",
    "        pred_opt_target = model(seqs_opt_target)\n",
    "\n",
    "        # Reshape predictions to (len(target_genes), -1)\n",
    "        pred_init_target = tf.reshape(pred_init_target, (len(target_genes), -1))\n",
    "        pred_opt_target = tf.reshape(pred_opt_target, (len(target_genes), -1))\n",
    "\n",
    "        # Compute average Log TPM per gene\n",
    "        init_log_tpm_target = tf.reduce_mean(pred_init_target, axis=1).numpy().astype('float')\n",
    "        opt_log_tpm_target = tf.reduce_mean(pred_opt_target, axis=1).numpy().astype('float')\n",
    "\n",
    "        # Compute overall average Log TPM across target genes\n",
    "        avg_init_log_tpm_target = np.average(init_log_tpm_target)\n",
    "        avg_opt_log_tpm_target = np.average(opt_log_tpm_target)\n",
    "\n",
    "        # Convert Log TPM to TPM for percentage improvement\n",
    "        # Assuming Log TPM is base-10 (common for TPM), TPM = 10^LogTPM\n",
    "        avg_init_tpm_target = np.power(10, avg_init_log_tpm_target)\n",
    "        avg_opt_tpm_target = np.power(10, avg_opt_log_tpm_target)\n",
    "\n",
    "        # Compute improvement\n",
    "        log_tpm_diff_target = avg_opt_log_tpm_target - avg_init_log_tpm_target\n",
    "        tpm_improvement_target = avg_opt_tpm_target - avg_init_tpm_target\n",
    "        # Percentage improvement based on TPM: ((opt - init) / init) * 100\n",
    "        if avg_init_tpm_target != 0:  # Avoid division by zero\n",
    "            tpm_percent_change_target = (tpm_improvement_target / avg_init_tpm_target) * 100\n",
    "        else:\n",
    "            tpm_percent_change_target = float('inf') if tpm_improvement_target > 0 else 0.0\n",
    "\n",
    "        # Handle negative and positive percentages\n",
    "        percent_str = f\"{tpm_percent_change_target:.2f}%\"\n",
    "        if tpm_percent_change_target < 0:\n",
    "            percent_str = f\"{tpm_percent_change_target:.2f}% (decrease)\"\n",
    "        elif tpm_percent_change_target > 0:\n",
    "            percent_str = f\"+{tpm_percent_change_target:.2f}% (increase)\"\n",
    "\n",
    "        # Print evaluation results\n",
    "        print(\"\\nEvaluation of Optimization on Target Genes (Log TPM):\")\n",
    "        print(f\"Original Genes: {gene_names}\")\n",
    "        print(f\"Target Genes: {target_genes}\")\n",
    "        print(\"\\nExpression Levels (Log TPM):\")\n",
    "        print(f\"  Average Initial Log TPM: {avg_init_log_tpm_target:.4f} (TPM: {avg_init_tpm_target:.4f})\")\n",
    "        print(f\"  Average Optimized Log TPM: {avg_opt_log_tpm_target:.4f} (TPM: {avg_opt_tpm_target:.4f})\")\n",
    "        print(f\"  Log TPM Difference: {log_tpm_diff_target:.4f}\")\n",
    "        print(f\"  TPM Improvement: {tpm_improvement_target:.4f} ({percent_str})\")\n",
    "\n",
    "        # Save evaluation results to a file\n",
    "        with open('./outputs/target_genes_evaluation.txt', 'w') as f:\n",
    "            f.write(\"Evaluation of Optimization on Target Genes (Log TPM)\\n\")\n",
    "            f.write(f\"Original Genes: {gene_names}\\n\")\n",
    "            f.write(f\"Target Genes: {target_genes}\\n\\n\")\n",
    "            f.write(\"Expression Levels (Log TPM):\\n\")\n",
    "            f.write(f\"  Average Initial Log TPM: {avg_init_log_tpm_target:.4f} (TPM: {avg_init_tpm_target:.4f})\\n\")\n",
    "            f.write(f\"  Average Optimized Log TPM: {avg_opt_log_tpm_target:.4f} (TPM: {avg_opt_tpm_target:.4f})\\n\")\n",
    "            f.write(f\"  Log TPM Difference: {log_tpm_diff_target:.4f}\\n\")\n",
    "            f.write(f\"  TPM Improvement: {tpm_improvement_target:.4f} ({percent_str})\\n\")\n",
    "\n",
    "        # Optional: Per-gene breakdown\n",
    "        print(\"\\nPer-Gene Expression Levels (Log TPM):\")\n",
    "        for gene, init_log, opt_log in zip(target_genes, init_log_tpm_target, opt_log_tpm_target):\n",
    "            init_tpm = np.power(10, init_log)\n",
    "            opt_tpm = np.power(10, opt_log)\n",
    "            tpm_diff = opt_tpm - init_tpm\n",
    "            if init_tpm != 0:\n",
    "                gene_percent = (tpm_diff / init_tpm) * 100\n",
    "            else:\n",
    "                gene_percent = float('inf') if tpm_diff > 0 else 0.0\n",
    "            gene_percent_str = f\"{gene_percent:.2f}%\"\n",
    "            if gene_percent < 0:\n",
    "                gene_percent_str = f\"{gene_percent:.2f}% (decrease)\"\n",
    "            elif gene_percent > 0:\n",
    "                gene_percent_str = f\"+{gene_percent:.2f}% (increase)\"\n",
    "            print(f\"  {gene}: Initial Log TPM = {init_log:.4f} (TPM: {init_tpm:.4f}), \"\n",
    "                f\"Optimized Log TPM = {opt_log:.4f} (TPM: {opt_tpm:.4f}), \"\n",
    "                f\"TPM Improvement = {tpm_diff:.4f} ({gene_percent_str})\")\n",
    "    \n",
    "\n",
    "    initial_target_expression = tf.cast(init_log_tpm_target, dtype=tf.float64)\n",
    "    initial_expression = tf.cast(initial_exp_per_gene, dtype=tf.float64)\n",
    "    optimized_expression_initial = tf.convert_to_tensor(best_scores_per_gene, dtype=tf.float64)\n",
    "\n",
    "    optimized_expression_target = tf.cast(opt_log_tpm_target, dtype=tf.float64)\n",
    "\n",
    "    # Store optimization results\n",
    "    results = {\n",
    "        'initial_genes': initial_genes,\n",
    "        'target_genes': target_genes,\n",
    "        'initial_expression': initial_expression,\n",
    "        'initial_target_expression': initial_target_expression,\n",
    "        'optimized_expression_initial': optimized_expression_initial,\n",
    "        'optimized_expression_target': optimized_expression_target,\n",
    "        'improvement_initial': 0.0,  # Will be calculated\n",
    "        'improvement_target': 0.0,  # Will be calculated\n",
    "        'percent_improvement_initial': 0.0,  # Will be calculated\n",
    "        'percent_improvement_target': 0.0  # Will be calculated\n",
    "    }\n",
    "    \n",
    "    # Calculate improvements\n",
    "    results['improvement_initial'] = np.power(10,results['optimized_expression_initial']) - np.power(10,results['initial_expression'])\n",
    "    results['improvement_target'] = np.power(10,results['optimized_expression_target']) - np.power(10,results['initial_target_expression'])\n",
    "    results['percent_improvement_initial'] = (results['improvement_initial'] / results['initial_expression']) * 100\n",
    "    results['percent_improvement_target'] = (results['improvement_target'] / results['initial_target_expression']) * 100\n",
    "    \n",
    "    # Save optimization data\n",
    "    os.makedirs('./outputs', exist_ok=True)\n",
    "    output_prefix = f\"optimization_{initial_genes[0]}_{target_genes[0]}\"\n",
    "    \n",
    "    # Save sequences\n",
    "    with open(f'./outputs/{output_prefix}_init_seqs_mix.txt', 'w') as f:\n",
    "        for item in seqs_gen_init:\n",
    "            f.write(f'{item}\\n')\n",
    "    \n",
    "    with open(f'./outputs/{output_prefix}_best_seqs_mix.txt', 'w') as f:\n",
    "        for item in best_seqs:\n",
    "            f.write(f'{item}\\n')\n",
    "    \n",
    "    # Save expression values\n",
    "    with open(f'./outputs/{output_prefix}_init_exps_mix.txt', 'w') as f:\n",
    "        for item in init_t:\n",
    "            f.write(f'{item}\\n')\n",
    "    \n",
    "    with open(f'./outputs/{output_prefix}_best_exps_mix.txt', 'w') as f:\n",
    "        for item in best_scores:\n",
    "            f.write(f'{item}\\n')\n",
    "    \n",
    "    with open(f'./outputs/{output_prefix}_opt_exps_mix.txt', 'w') as f:\n",
    "        for item in opt_t:\n",
    "            f.write(f'{item}\\n')\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nOptimization completed for {len(initial_genes)} initial genes and {len(target_genes)} target genes\")\n",
    "        print(f\"Initial genes: {initial_genes}\")\n",
    "        print(f\"Target genes: {target_genes}\")\n",
    "        print(f\"Initial expression (training genes): {results['initial_expression']}\")\n",
    "        print(f\"Initial expression (target genes): {results['initial_target_expression']}\")\n",
    "        print(f\"Optimized expression (training genes): {results['optimized_expression_initial']}\")\n",
    "        print(f\"Optimized expression (target genes): {results['optimized_expression_target']}\")\n",
    "        print(f\"Improvement (training genes): {results['improvement_initial']} ({results['percent_improvement_initial']}%)\")\n",
    "        print(f\"Improvement (target genes): {results['improvement_target']} ({results['percent_improvement_target']}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def run_multiple_optimizations(gene_sets, batch_size=100, steps=50, lr=0.001):\n",
    "    \"\"\"Run optimization for multiple gene sets.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, gene_set in enumerate(gene_sets):\n",
    "        print(f\"\\n=== Optimizing Gene Set {i+1}/{len(gene_sets)} ===\")\n",
    "        initial_genes = gene_set['initial']\n",
    "        target_genes = gene_set['target']\n",
    "        \n",
    "        # Run optimization\n",
    "        set_results = optimize_gene_set(\n",
    "            initial_genes=initial_genes,\n",
    "            target_genes=target_genes,\n",
    "            batch_size=batch_size,\n",
    "            steps=steps,\n",
    "            lr=lr,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        results.append(set_results)\n",
    "        \n",
    "    return results\n",
    "\n",
    "def plot_optimization_results(results, output_path='./outputs/optimization_results.png'):\n",
    "    \"\"\"Create a bar plot of optimization results.\"\"\"\n",
    "    # Extract data for plotting\n",
    "    sets = [f\"Set {i+1}\" for i in range(len(results))]\n",
    "    initial_improvements = [r['percent_improvement_initial'] for r in results]\n",
    "    target_improvements = [r['percent_improvement_target'] for r in results]\n",
    "    \n",
    "    # Set up plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Set width of bars\n",
    "    barWidth = 0.35\n",
    "    \n",
    "    # Set positions of bars on X axis\n",
    "    r1 = np.arange(len(sets))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    \n",
    "    # Create bars\n",
    "    initial_improvements = tf.math.reduce_mean(initial_improvements, axis=1).numpy()\n",
    "    target_improvements = tf.math.reduce_mean(target_improvements, axis=1).numpy()\n",
    "    ax.bar(r1, initial_improvements, width=barWidth, label='Initial Genes', color='blue', alpha=0.7)\n",
    "    ax.bar(r2, target_improvements, width=barWidth, label='Target Genes', color='green', alpha=0.7)\n",
    "    \n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Gene Sets', fontsize=12)\n",
    "    ax.set_ylabel('Expression Improvement (%)', fontsize=12)\n",
    "    ax.set_title('5\\' UTR Optimization Results Across Gene Sets', fontsize=14)\n",
    "    ax.set_xticks([r + barWidth/2 for r in range(len(sets))])\n",
    "    ax.set_xticklabels(sets)\n",
    "    \n",
    "    # Add a horizontal line at y=0\n",
    "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # Add values on top of bars\n",
    "    for i, v in enumerate(initial_improvements):\n",
    "        ax.text(r1[i], v + 5, f\"{v:.1f}%\", ha='center', va='bottom')\n",
    "    \n",
    "    for i, v in enumerate(target_improvements):\n",
    "        ax.text(r2[i], v + 5, f\"{v:.1f}%\", ha='center', va='bottom')\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add grid for better readability\n",
    "    ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    print(f\"Plot saved to {output_path}\")\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "def plot_expression_levels(results, output_path='./outputs/expression_levels.png'):\n",
    "    \"\"\"Create a bar plot of expression levels before and after optimization.\"\"\"\n",
    "    # Extract data for plotting\n",
    "    sets = [f\"Set {i+1}\" for i in range(len(results))]\n",
    "    initial_expr = [r['initial_expression'].numpy() for r in results]\n",
    "    initial_target_expr = [r['initial_target_expression'].numpy() for r in results]  # Added initial target expression\n",
    "    optimized_initial = [r['optimized_expression_initial'].numpy() for r in results]\n",
    "    optimized_target = [r['optimized_expression_target'].numpy() for r in results]\n",
    "    \n",
    "    # Set up plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Set width of bars\n",
    "    barWidth = 0.2\n",
    "    \n",
    "    # Set positions of bars on X axis\n",
    "    r1 = np.arange(len(sets))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    r3 = [x + barWidth for x in r2]\n",
    "    r4 = [x + barWidth for x in r3]\n",
    "    \n",
    "    initial_expr = tf.math.reduce_mean(initial_expr, axis=1).numpy()\n",
    "    initial_target_expr = tf.math.reduce_mean(initial_target_expr, axis=1).numpy()\n",
    "    optimized_initial = tf.math.reduce_mean(optimized_initial, axis=1).numpy()\n",
    "    optimized_target = tf.math.reduce_mean(optimized_target, axis=1).numpy()\n",
    "    # Create bars\n",
    "    ax.bar(r1, initial_expr, width=barWidth, label='Initial (Training Genes)', color='gray', alpha=0.7)\n",
    "    ax.bar(r2, initial_target_expr, width=barWidth, label='Initial (Target Genes)', color='purple', alpha=0.7)\n",
    "    ax.bar(r3, optimized_initial, width=barWidth, label='Optimized (Training Genes)', color='blue', alpha=0.7)\n",
    "    ax.bar(r4, optimized_target, width=barWidth, label='Optimized (Target Genes)', color='green', alpha=0.7)\n",
    "    \n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Gene Sets', fontsize=12)\n",
    "    ax.set_ylabel('Expression Level (log TPM)', fontsize=12)\n",
    "    ax.set_title('Expression Levels Before and After Optimization', fontsize=14)\n",
    "    ax.set_xticks([r + barWidth*1.5 for r in range(len(sets))])\n",
    "    ax.set_xticklabels(sets)\n",
    "    \n",
    "    # Add values on top of bars\n",
    "    for i, v in enumerate(initial_expr):\n",
    "        ax.text(r1[i], v + 0.1, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "    \n",
    "    for i, v in enumerate(initial_target_expr):\n",
    "        ax.text(r2[i], v + 0.1, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "    \n",
    "    for i, v in enumerate(optimized_initial):\n",
    "        ax.text(r3[i], v + 0.1, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "        \n",
    "    for i, v in enumerate(optimized_target):\n",
    "        ax.text(r4[i], v + 0.1, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add grid for better readability\n",
    "    ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    print(f\"Plot saved to {output_path}\")\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Define 8 gene sets (initial and target genes)\n",
    "    gene_sets = [\n",
    "        {\n",
    "            'initial': [\"MYOC\", \"TIGD4\", \"ATP6V1B2\", \"TAGLN\", \"COX7A2L\", \"IFNGR2\", \"TNFRSF21\", \"SETD6\"],\n",
    "            'target': [\"ANTXR2\", \"NFIL3\", \"UNC13D\", \"DHRS2\", \"RPS13\", \"HBD\", \"METAP1D\", \"NCALD\"]\n",
    "        },\n",
    "        {\n",
    "            'initial': [\"BRCA1\", \"TNFAIP3\", \"TRIM36\", \"TEX55\", \"LEMD2\", \"LSG1\", \"SGIP1\", \"MAD2L1\"],\n",
    "            'target': [\"DAZL\", \"PPARG\", \"CDKN1A\", \"BAX\", \"MDM2\", \"BCL2\", \"TP53\", \"VEGFA\"]\n",
    "        },\n",
    "        {\n",
    "            'initial': [\"IL6\", \"TNF\", \"IFNG\", \"IL10\", \"TGFB1\", \"IL2\", \"IL4\", \"IL17A\"],\n",
    "            'target': [\"CD4\", \"CD8A\", \"CD19\", \"CD3E\", \"CD14\", \"FOXP3\", \"CTLA4\", \"PD1\"]\n",
    "        },\n",
    "        {\n",
    "            'initial': [\"SOX2\", \"POU5F1\", \"NANOG\", \"KLF4\", \"MYC\", \"LIN28\", \"DNMT3B\", \"ZFP42\"],\n",
    "            'target': [\"GATA1\", \"GATA2\", \"TAL1\", \"RUNX1\", \"MYB\", \"GYPA\", \"HBB\", \"HBA1\"]\n",
    "        },\n",
    "        {\n",
    "            'initial': [\"INSR\", \"IGF1R\", \"IRS1\", \"PIK3CA\", \"AKT1\", \"MTOR\", \"PTEN\", \"GSK3B\"],\n",
    "            'target': [\"PPARG\", \"ADIPOQ\", \"LEP\", \"FABP4\", \"PLIN1\", \"UCP1\", \"ADRB3\", \"CPT1A\"]\n",
    "        },\n",
    "        {\n",
    "            'initial': [\"APP\", \"PSEN1\", \"PSEN2\", \"APOE\", \"MAPT\", \"BACE1\", \"GSK3B\", \"CDK5\"],\n",
    "            'target': [\"BDNF\", \"NGF\", \"GDNF\", \"NTF3\", \"NTRK1\", \"NTRK2\", \"NGFR\", \"GFAP\"]\n",
    "        },\n",
    "        {\n",
    "            'initial': [\"PCNA\", \"CCNA2\", \"CCNB1\", \"CDK1\", \"CDK2\", \"E2F1\", \"RB1\", \"TP53\"],\n",
    "            'target': [\"CDKN1A\", \"CDKN1B\", \"CDKN2A\", \"CDKN2B\", \"ATM\", \"ATR\", \"CHEK1\", \"CHEK2\"]\n",
    "        },\n",
    "        {\n",
    "            'initial': [\"HIF1A\", \"VEGFA\", \"EGFR\", \"KDR\", \"FLT1\", \"NRP1\", \"ANGPT1\", \"TEK\"],\n",
    "            'target': [\"CDH5\", \"PECAM1\", \"VWF\", \"ICAM1\", \"VCAM1\", \"SELE\", \"EDN1\", \"NOS3\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Run optimization for all gene sets\n",
    "    print(\"Starting optimization for 8 gene sets...\")\n",
    "    results = run_multiple_optimizations(gene_sets, steps=1000, lr=0.005)\n",
    "    \n",
    "    # Save results to a CSV file\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('./outputs/optimization_results.csv', index=False)\n",
    "    print(\"Results saved to ./outputs/optimization_results.csv\")\n",
    "    \n",
    "    # Create plots to visualize results\n",
    "    plot_optimization_results(results)\n",
    "    plot_expression_levels(results)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    avg_initial_improvement = np.mean([r['percent_improvement_initial'] for r in results])\n",
    "    avg_target_improvement = np.mean([r['percent_improvement_target'] for r in results])\n",
    "    \n",
    "    print(\"\\n=== Summary Statistics ===\")\n",
    "    print(f\"Average improvement for initial genes: {avg_initial_improvement:.2f}%\")\n",
    "    print(f\"Average improvement for target genes: {avg_target_improvement:.2f}%\")\n",
    "    print(f\"Ratio of target to initial improvement: {avg_target_improvement/avg_initial_improvement:.2f}\")\n",
    "    \n",
    "    # Analyze gene set performance\n",
    "    best_initial_set_idx = np.argmax([r['percent_improvement_initial'] for r in results])\n",
    "    best_target_set_idx = np.argmax([r['percent_improvement_target'] for r in results])\n",
    "    \n",
    "    print(\"\\n=== Best Performing Gene Sets ===\")\n",
    "    print(f\"Best initial gene set: Set {best_initial_set_idx+1}\")\n",
    "    print(f\"  Initial genes: {gene_sets[best_initial_set_idx]['initial']}\")\n",
    "    print(f\"  Improvement: {np.mean(results[best_initial_set_idx]['percent_improvement_initial'].numpy()):.2f}%\")\n",
    "    \n",
    "    print(f\"Best target gene set: Set {best_target_set_idx+1}\")\n",
    "    print(f\"  Target genes: {gene_sets[best_target_set_idx]['target']}\")\n",
    "    print(f\"  Improvement: {np.mean(results[best_target_set_idx]['percent_improvement_target'].numpy()):.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
