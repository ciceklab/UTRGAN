{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "random.seed(1337)\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import pandas as pd\n",
    "import torch\n",
    "from framepool import *\n",
    "from util import *\n",
    "import keras\n",
    "\n",
    "import random\n",
    "random.seed(1337)\n",
    "import os\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, sys\n",
    "\n",
    "DATA = './../../data/utrdb2.csv'\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "TASK = \"te\"\n",
    "GPU = '-1'\n",
    "STEPS = 100\n",
    "\n",
    "if GPU == '-1':\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
    "    device = 'cuda'\n",
    "    if ',' in GPU:\n",
    "        device = 'cuda:1'\n",
    "\n",
    "def prepare_mttrans(seqs):\n",
    "    seqs_init = torch.tensor(np.array(one_hot_all_motif(seqs),dtype=np.float32))\n",
    "\n",
    "    seqs_init = torch.transpose(seqs_init, 1, 2)\n",
    "    seqs_init = torch.tensor(seqs_init,dtype=torch.float32).to(device)\n",
    "    return seqs_init\n",
    "\n",
    "def prepare_framepool(seqs):\n",
    "    return tf.convert_to_tensor(np.array([encode_seq_framepool(seq) for seq in seqs]),dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "DIM = 40\n",
    "SEQ_LEN = 128\n",
    "UTR_LEN = 128\n",
    "gpath = './../../models/checkpoint_3000.h5'\n",
    "mrl_path = './../../models/utr_model_combined_residual_new.h5'\n",
    "\n",
    "path = './script/checkpoint/RL_hard_share_MTL/3R/schedule_MTL-model_best_cv1.pth'\n",
    "val_path = './script/checkpoint/RL_hard_share_MTL/3M/schedule_lr-model_best_cv1.pth'\n",
    "\n",
    "\n",
    "\n",
    "if TASK == 'te':\n",
    "    path = './script/checkpoint/RL_hard_share_MTL/3R/schedule_MTL-model_best_cv1.pth'\n",
    "    OPT = 'TE'\n",
    "else:\n",
    "    path = './script/checkpoint/RL_hard_share_MTL/3M/schedule_lr-model_best_cv1.pth'\n",
    "    OPT = 'FMRL'\n",
    "\n",
    "\n",
    "out_folder = './outputs/'\n",
    "os.makedirs(out_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/var/folders/by/ns833bsx3yg5f8j5w0z5lmsw0000gq/T/ipykernel_88318/3924019252.py:227: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seqs = torch.tensor(seqs.to(device), requires_grad=True)\n",
      "100%|██████████| 100/100 [01:44<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Initial Pred: -0.4125024378299713\n",
      "Max Initial Pred: 0.45564794540405273\n",
      "Average Opt. Pred: 0.4506695866584778\n",
      "Max Opt. Pred: 1.3088536262512207\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def select_best(scores, seqs):\n",
    "    selected_scores = []\n",
    "    selected_seqs = []\n",
    "    for i in range(len(scores[0])):\n",
    "        best = scores[0][i]\n",
    "        best_seq = seqs[0][i]\n",
    "        for j in range(len(scores)-1):\n",
    "            if scores[j+1][i] > best:\n",
    "                best = scores[j+1][i]\n",
    "                best_seq = seqs[j+1][i]\n",
    "        selected_scores.append(best)\n",
    "        selected_seqs.append(best_seq)\n",
    "\n",
    "    return selected_seqs, selected_scores\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    if OPT == 'FMRL':\n",
    "        Optimize_FrameSlice = True\n",
    "    else:\n",
    "        Optimize_FrameSlice = False\n",
    "\n",
    "\n",
    "\n",
    "    if Optimize_FrameSlice:\n",
    "        model = load_framepool(mrl_path)\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        model = torch.load(path,map_location=torch.device(device))['state_dict']  \n",
    "        model.train()   \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    wgan = tf.keras.models.load_model(gpath)\n",
    "\n",
    "    \"\"\"\n",
    "    Data:\n",
    "    \"\"\"\n",
    "\n",
    "    tf.random.set_seed(33)\n",
    "    np.random.seed(33)\n",
    "\n",
    "    diffs = []\n",
    "    init_exps = []\n",
    "    opt_exps = []\n",
    "    orig_vals = []\n",
    "\n",
    "    DIM = 40\n",
    "    MAX_LEN = 128\n",
    "    LR = np.exp(-LR)\n",
    "\n",
    "    tempnoise = tf.random.normal(shape=[BATCH_SIZE,DIM])\n",
    "    selectednoise = tempnoise\n",
    "\n",
    "    best = 10\n",
    "\n",
    "    LOW_START = False\n",
    "\n",
    "\n",
    "    if LOW_START:\n",
    "    \n",
    "        for i in range(10000):\n",
    "            tempnoise = tf.random.normal(shape=[BATCH_SIZE,DIM])\n",
    "            sequences = wgan(tempnoise)\n",
    "\n",
    "            seqs_gen = recover_seq(sequences, rev_rna_vocab)\n",
    "            seqs_str = seqs_gen\n",
    "\n",
    "            shape_ = tf.shape(np.array([encode_seq_framepool(seq) for seq in recover_seq(sequences, rev_rna_vocab)]))\n",
    "\n",
    "            seqs = tf.convert_to_tensor(np.array([encode_seq_framepool(seq) for seq in recover_seq(sequences, rev_rna_vocab)]),dtype=tf.float32)\n",
    "\n",
    "            \n",
    "            pred =  model(seqs)\n",
    "\n",
    "            t = tf.reshape(pred,(-1))\n",
    "            t = t.numpy().astype('float')\n",
    "            score = np.mean(t)\n",
    "\n",
    "            if score < best:\n",
    "                best = score\n",
    "                selectednoise = tempnoise\n",
    "        noise = tf.Variable(selectednoise)\n",
    "    else:\n",
    "        noise = tf.Variable(tf.random.normal(shape=[BATCH_SIZE,DIM]))\n",
    "    \n",
    "\n",
    "    noise_small = tf.random.normal(shape=[BATCH_SIZE,DIM],stddev=1e-4)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=np.power(np.e,LR))\n",
    "\n",
    "    '''\n",
    "    Optimization takes place here.\n",
    "    '''\n",
    "\n",
    "    bind_scores_list = []\n",
    "    bind_scores_means = []\n",
    "    sequences_list = []\n",
    "\n",
    "    means = []\n",
    "    maxes = []\n",
    "    iters_ = []\n",
    "\n",
    "    OPTIMIZE = True\n",
    "\n",
    "    DNA_SEL = False\n",
    "\n",
    "\n",
    "    sequences_init = wgan(noise)\n",
    "\n",
    "    gen_seqs_init = sequences_init.numpy().astype('float')\n",
    "\n",
    "    seqs_gen_init = recover_seq(gen_seqs_init, rev_rna_vocab)\n",
    "\n",
    "    init_pos, init_neg = motif_count(seqs_gen_init)\n",
    "    \n",
    "    if Optimize_FrameSlice:\n",
    "        seqs = prepare_framepool(seqs_gen_init)\n",
    "\n",
    "        seqs_init = prepare_mttrans(seqs_gen_init)\n",
    "\n",
    "        pred_init = model(seqs)\n",
    "        \n",
    "    else:\n",
    "\n",
    "\n",
    "        one_hots = one_hot_all_motif(np.array(seqs_gen_init))\n",
    "        seqs = torch.tensor(one_hots,dtype=torch.double)\n",
    "        seqs = torch.transpose(seqs, 1, 2)\n",
    "        seqs = seqs.float().to(device)\n",
    "\n",
    "\n",
    "        pred_init = model.forward(seqs)\n",
    "    \n",
    "    if Optimize_FrameSlice:\n",
    "\n",
    "        t = tf.reshape(pred_init,(-1))\n",
    "\n",
    "        init_t = t.numpy().astype('float')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        t = torch.flatten(pred_init)\n",
    "        t.float()\n",
    "        \n",
    "        init_t = t.cpu().detach().numpy()\n",
    "\n",
    "    init_exp = np.mean(init_t)\n",
    "\n",
    "    max_init = np.max(init_t)\n",
    "\n",
    "    min_init = np.min(init_t)\n",
    "    \n",
    "    predicted_mrls = []\n",
    "\n",
    "    STEPS = STEPS\n",
    "\n",
    "    seqs_collection = []\n",
    "    scores_collection = []\n",
    "    if OPTIMIZE:\n",
    "        iter_ = 0\n",
    "        for opt_iter in tqdm(range(int(STEPS))):\n",
    "            \n",
    "            with tf.GradientTape() as gtape:\n",
    "                gtape.watch(noise)\n",
    "                sequences = wgan(noise)\n",
    "\n",
    "                seqs_gen = recover_seq(sequences, rev_rna_vocab)\n",
    "                seqs_collection.append(seqs_gen)\n",
    "                seqs_str = seqs_gen\n",
    "                \n",
    "                if Optimize_FrameSlice:\n",
    "\n",
    "                    seqs = tf.convert_to_tensor(np.array([encode_seq_framepool(seq) for seq in recover_seq(sequences, rev_rna_vocab)]),dtype=tf.float32)\n",
    "                \n",
    "                else:\n",
    "                    seqs = torch.tensor(np.array(one_hot_all_motif(seqs_gen),dtype=np.float32))    \n",
    "\n",
    "                if Optimize_FrameSlice:\n",
    "\n",
    "                    with tf.GradientTape() as ptape:\n",
    "                        ptape.watch(seqs)\n",
    "\n",
    "                        pred =  model(seqs)\n",
    "                        score = tf.reduce_mean(pred)\n",
    "                        t = tf.reshape(pred,(-1))\n",
    "                        mx = t.numpy().astype('float')\n",
    "                        scores_collection.append(mx)\n",
    "                        mx = np.max(mx)\n",
    "                        \n",
    "                        sum_ = tf.reduce_sum(t).numpy().astype('float')\n",
    "                        \n",
    "                        maxes.append(mx)\n",
    "                        predicted_mrls.append(sum_/BATCH_SIZE)\n",
    "                        means.append(sum_/BATCH_SIZE)\n",
    "\n",
    "                    g1 = ptape.gradient(score,seqs)\n",
    "\n",
    "                    OPTIMIZE_FULL = False\n",
    "                    if OPTIMIZE_FULL:\n",
    "                        tmp_g = g1.numpy().astype('float')\n",
    "                        tmp_seqs = seqs_gen\n",
    "                        tmp_lst = np.zeros(shape=(BATCH_SIZE,MAX_LEN,5))\n",
    "                        for i in range(len(tmp_seqs)):\n",
    "                            \n",
    "                            len_ = len(tmp_seqs[i])\n",
    "                            edited_g = tmp_g[i][:len_,:]\n",
    "                            edited_g = np.pad(edited_g,((0,MAX_LEN-len_),(0,1)),'constant')   \n",
    "                            tmp_lst[i] = edited_g   \n",
    "                        \n",
    "                        g1 = tf.convert_to_tensor(tmp_lst,dtype=tf.float32)\n",
    "\n",
    "                    else:\n",
    "                        \n",
    "                        g1 = tf.pad(g1,tf.constant([[0, 0], [0, 0], [0, 1]]),\"CONSTANT\")\n",
    "\n",
    "                    g1 = tf.math.scalar_mul(-1.0,g1)\n",
    "\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    seqs = torch.transpose(seqs, 1, 2)\n",
    "                    seqs = seqs.float()\n",
    "                    seqs = torch.tensor(seqs.to(device), requires_grad=True)\n",
    "                    pred = model(seqs)\n",
    "                    pred = torch.flatten(pred)\n",
    "                    predicted_mrls.append(np.average(pred.cpu().detach().numpy()))\n",
    "                    scores_collection.append(pred.cpu().detach().numpy())\n",
    "                    score = torch.mean(pred)\n",
    "                    t = torch.flatten(pred)\n",
    "                    mx = t.cpu().detach().numpy()\n",
    "                    mx = np.max(mx)\n",
    "                    \n",
    "                    sum_ = torch.mean(t).cpu().detach().numpy()\n",
    "                    \n",
    "                    maxes.append(mx)\n",
    "                    means.append(sum_/BATCH_SIZE)\n",
    "                    pred.backward(torch.ones_like(pred))\n",
    "                    \n",
    "                    g1 = seqs.grad\n",
    "                    \n",
    "                    g1 = g1.cpu().detach().numpy()\n",
    "                    g1 = tf.convert_to_tensor(g1)\n",
    "                    g1 = tf.transpose(g1, perm=[0,2,1])\n",
    "                    g1 = tf.pad(g1,tf.constant([[0, 0], [0, 0], [0, 1]]),\"CONSTANT\")\n",
    "                    g1 = tf.math.scalar_mul(-1.0,g1)\n",
    "                \n",
    "                \n",
    "                g2 = gtape.gradient(sequences,noise,output_gradients=g1)\n",
    "\n",
    "            a1 = g2 + noise_small\n",
    "            change = [(a1,noise)]\n",
    "            optimizer.apply_gradients(change)\n",
    "\n",
    "            iters_.append(iter_)\n",
    "            iter_ += 1\n",
    "\n",
    "        best_seqs, best_scores = select_best(scores_collection, seqs_collection)\n",
    "\n",
    "        sequences_opt = wgan(noise)\n",
    "        \n",
    "        gen_seqs_opt = sequences_opt.numpy().astype('float')\n",
    "\n",
    "        seqs_gen_opt = recover_seq(gen_seqs_opt, rev_rna_vocab)\n",
    "\n",
    "        opt_pos, opt_neg = motif_count(seqs_gen_opt)\n",
    "        \n",
    "        if Optimize_FrameSlice:\n",
    "            \n",
    "            seqs_opt = prepare_framepool(seqs_gen_opt)\n",
    "\n",
    "\n",
    "        \n",
    "        else: \n",
    "\n",
    "            one_hots = np.array(one_hot_all_motif(seqs_gen_opt))\n",
    "            # print(np.shape(one_hots))\n",
    "            seqs = torch.tensor(one_hots,dtype=torch.double)\n",
    "            seqs = torch.transpose(seqs, 1, 2)\n",
    "            seqs = seqs.float().to(device)\n",
    "\n",
    "        pred_opt = model(seqs)\n",
    "        \n",
    "        if Optimize_FrameSlice:\n",
    "\n",
    "            t = tf.reshape(pred_opt,(-1))\n",
    "            \n",
    "            opt_t = t.numpy().astype('float')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            t = torch.flatten(pred_opt)\n",
    "        \n",
    "        \n",
    "            opt_t = t.cpu().detach().numpy()\n",
    "\n",
    "        opt_exp = np.mean(opt_t)\n",
    "\n",
    "        min_opt = np.min(opt_t)\n",
    "        max_opt = np.max(opt_t)\n",
    "\n",
    "        with open(f'./outputs/init_mrl_{OPT}.txt', 'w') as f:\n",
    "            f.writelines([str(x)+'\\n' for x in init_t])\n",
    "\n",
    "        with open(f'./outputs/opt_mrl_{OPT}.txt', 'w') as f:\n",
    "            f.writelines([str(x)+'\\n' for x in best_scores])\n",
    "\n",
    "        with open(f'./outputs/opt_seqs_{OPT}.txt', 'w') as f:\n",
    "            f.writelines([str(x)+'\\n' for x in best_seqs])\n",
    "\n",
    "        with open(f'./outputs/init_seqs_{OPT}.txt', 'w') as f:\n",
    "            f.writelines([str(x)+'\\n' for x in seqs_gen_init])\n",
    "    \n",
    "\n",
    "        print(f\"Average Initial Pred: {np.average(init_t)}\")\n",
    "        print(f\"Max Initial Pred: {np.max(init_t)}\")\n",
    "        print(f\"Average Opt. Pred: {np.average(best_scores)}\")\n",
    "        print(f\"Max Opt. Pred: {np.max(best_scores)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene: BRCA1 (Ensembl ID: ENSG00000012048)\n",
      "\n",
      "Genome Coordinates:\n",
      "Chromosome: 17\n",
      "Start: 43044295\n",
      "End: 43170245\n",
      "Strand: -\n",
      "\n",
      "Transcription Start Site (TSS):\n",
      "Chromosome: 17\n",
      "Position: 43170245\n",
      "\n",
      "Xpresso Input Features:\n",
      "Promoter sequence length: 10501 bp\n",
      "GC content: 0.46\n",
      "5' UTR length: 113 bp\n",
      "3' UTR length: 1383 bp\n",
      "\n",
      "Canonical Transcript:\n",
      "Transcript ID: ENST00000357654\n",
      "Start: 43044295\n",
      "End: 43125364\n",
      "Is Canonical: Yes\n",
      "\n",
      "Canonical UTRs:\n",
      "  5' UTR: 43125271-43125364 (length: 94 bp)\n",
      "  5' UTR: 43124097-43124115 (length: 19 bp)\n",
      "  3' UTR: 43044295-43045677 (length: 1383 bp)\n",
      "\n",
      "Total 5' UTR length: 113 bp\n",
      "Total 3' UTR length: 1383 bp\n",
      "Total UTR length: 1496 bp\n",
      "\n",
      "Exon count: 23\n",
      "Exon junction density: 0.000271\n",
      "\n",
      "All Transcripts:\n",
      "\n",
      "Transcript 1: ENST00000357654 (CANONICAL)\n",
      "Start: 43044295\n",
      "End: 43125364\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125364\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044295-43045677\n",
      "\n",
      "Transcript 2: ENST00000497488 \n",
      "Start: 43044295\n",
      "End: 43125300\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125300\n",
      "  5' UTR: 43094643-43094860\n",
      "  3' UTR: 43044295-43045677\n",
      "\n",
      "Transcript 3: ENST00000489037 \n",
      "Start: 43044295\n",
      "End: 43125321\n",
      "UTRs:\n",
      "  5' UTR: 43125182-43125321\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044295-43045677\n",
      "\n",
      "Transcript 4: ENST00000478531 \n",
      "Start: 43044295\n",
      "End: 43125359\n",
      "UTRs:\n",
      "  5' UTR: 43125277-43125359\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044295-43045677\n",
      "\n",
      "Transcript 5: ENST00000473961 \n",
      "Start: 43044295\n",
      "End: 43125364\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125364\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044295-43045677\n",
      "\n",
      "Transcript 6: ENST00000477152 \n",
      "Start: 43044295\n",
      "End: 43125364\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125364\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044295-43045677\n",
      "\n",
      "Transcript 7: ENST00000352993 \n",
      "Start: 43044295\n",
      "End: 43125370\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125370\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044295-43045677\n",
      "\n",
      "Transcript 8: ENST00000493919 \n",
      "Start: 43044295\n",
      "End: 43125402\n",
      "UTRs:\n",
      "  5' UTR: 43125277-43125402\n",
      "  5' UTR: 43124017-43124115\n",
      "  5' UTR: 43106527-43106533\n",
      "  3' UTR: 43044295-43045677\n",
      "\n",
      "Transcript 9: ENST00000494123 \n",
      "Start: 43044295\n",
      "End: 43125450\n",
      "UTRs:\n",
      "  5' UTR: 43125277-43125450\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044295-43045677\n",
      "\n",
      "Transcript 10: ENST00000471181 \n",
      "Start: 43044295\n",
      "End: 43125483\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125483\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044295-43045677\n",
      "\n",
      "Transcript 11: ENST00000652672 \n",
      "Start: 43044295\n",
      "End: 43125483\n",
      "UTRs:\n",
      "  5' UTR: 43125277-43125483\n",
      "  5' UTR: 43124017-43124115\n",
      "  5' UTR: 43121558-43121676\n",
      "  5' UTR: 43115726-43115779\n",
      "  5' UTR: 43106527-43106533\n",
      "  3' UTR: 43044295-43045677\n",
      "\n",
      "Transcript 12: ENST00000634433 \n",
      "Start: 43044295\n",
      "End: 43170245\n",
      "UTRs:\n",
      "  5' UTR: 43170126-43170245\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044295-43045677\n",
      "\n",
      "Transcript 13: ENST00000476777 \n",
      "Start: 43044298\n",
      "End: 43125360\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125360\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044298-43045677\n",
      "\n",
      "Transcript 14: ENST00000700081 \n",
      "Start: 43044302\n",
      "End: 43050409\n",
      "\n",
      "Transcript 15: ENST00000470026 \n",
      "Start: 43044304\n",
      "End: 43125343\n",
      "UTRs:\n",
      "  5' UTR: 43125182-43125343\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044304-43045677\n",
      "\n",
      "Transcript 16: ENST00000713676 \n",
      "Start: 43044304\n",
      "End: 43125343\n",
      "UTRs:\n",
      "  5' UTR: 43125277-43125343\n",
      "  5' UTR: 43124097-43124102\n",
      "  3' UTR: 43044304-43045677\n",
      "\n",
      "Transcript 17: ENST00000618469 \n",
      "Start: 43044304\n",
      "End: 43125364\n",
      "UTRs:\n",
      "  5' UTR: 43124737-43125364\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044304-43045677\n",
      "\n",
      "Transcript 18: ENST00000461574 \n",
      "Start: 43044304\n",
      "End: 43125370\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125370\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044304-43045677\n",
      "\n",
      "Transcript 19: ENST00000644555 \n",
      "Start: 43044304\n",
      "End: 43125370\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125370\n",
      "  5' UTR: 43124017-43124115\n",
      "  5' UTR: 43119121-43119265\n",
      "  5' UTR: 43115726-43115779\n",
      "  5' UTR: 43106527-43106533\n",
      "  3' UTR: 43044304-43045677\n",
      "\n",
      "Transcript 20: ENST00000468300 \n",
      "Start: 43044805\n",
      "End: 43125451\n",
      "UTRs:\n",
      "  5' UTR: 43125277-43125451\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43044805-43045783\n",
      "\n",
      "Transcript 21: ENST00000700082 \n",
      "Start: 43044981\n",
      "End: 43048473\n",
      "\n",
      "Transcript 22: ENST00000644379 \n",
      "Start: 43045086\n",
      "End: 43125364\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125364\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43045086-43045677\n",
      "\n",
      "Transcript 23: ENST00000484087 \n",
      "Start: 43045434\n",
      "End: 43125343\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125343\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43045434-43045677\n",
      "\n",
      "Transcript 24: ENST00000586385 \n",
      "Start: 43045563\n",
      "End: 43125329\n",
      "UTRs:\n",
      "  5' UTR: 43125186-43125329\n",
      "  3' UTR: 43045563-43045677\n",
      "\n",
      "Transcript 25: ENST00000591534 \n",
      "Start: 43045563\n",
      "End: 43125329\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125329\n",
      "  5' UTR: 43074479-43074521\n",
      "  3' UTR: 43045563-43045677\n",
      "\n",
      "Transcript 26: ENST00000591849 \n",
      "Start: 43045563\n",
      "End: 43125329\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125329\n",
      "  5' UTR: 43050093-43050190\n",
      "  3' UTR: 43045563-43045677\n",
      "\n",
      "Transcript 27: ENST00000493795 \n",
      "Start: 43045629\n",
      "End: 43125402\n",
      "UTRs:\n",
      "  5' UTR: 43125277-43125402\n",
      "  5' UTR: 43124017-43124115\n",
      "  5' UTR: 43106527-43106533\n",
      "  3' UTR: 43045629-43045677\n",
      "\n",
      "Transcript 28: ENST00000461221 \n",
      "Start: 43045678\n",
      "End: 43125288\n",
      "UTRs:\n",
      "  5' UTR: 43125182-43125288\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43104868-43104954\n",
      "  3' UTR: 43104122-43104261\n",
      "  3' UTR: 43099775-43099877\n",
      "  3' UTR: 43097244-43097289\n",
      "  3' UTR: 43095846-43095922\n",
      "  3' UTR: 43091435-43094860\n",
      "  3' UTR: 43090944-43091032\n",
      "  3' UTR: 43082404-43082575\n",
      "  3' UTR: 43076488-43076614\n",
      "  3' UTR: 43074331-43074521\n",
      "  3' UTR: 43070928-43071238\n",
      "  3' UTR: 43067608-43067695\n",
      "  3' UTR: 43063874-43063951\n",
      "  3' UTR: 43063333-43063373\n",
      "  3' UTR: 43057052-43057135\n",
      "  3' UTR: 43051063-43051117\n",
      "  3' UTR: 43049121-43049194\n",
      "  3' UTR: 43047643-43047703\n",
      "  3' UTR: 43045678-43045802\n",
      "\n",
      "Transcript 29: ENST00000491747 \n",
      "Start: 43045678\n",
      "End: 43125356\n",
      "UTRs:\n",
      "  5' UTR: 43125277-43125356\n",
      "  5' UTR: 43124097-43124115\n",
      "\n",
      "Transcript 30: ENST00000472490 \n",
      "Start: 43067274\n",
      "End: 43071066\n",
      "\n",
      "Transcript 31: ENST00000700182 \n",
      "Start: 43070344\n",
      "End: 43125343\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125343\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43070344-43070885\n",
      "\n",
      "Transcript 32: ENST00000621897 \n",
      "Start: 43076488\n",
      "End: 43082760\n",
      "\n",
      "Transcript 33: ENST00000354071 \n",
      "Start: 43091098\n",
      "End: 43125315\n",
      "\n",
      "Transcript 34: ENST00000700183 \n",
      "Start: 43094033\n",
      "End: 43125343\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125343\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43110465-43110534\n",
      "  3' UTR: 43106478-43106533\n",
      "  3' UTR: 43104868-43104956\n",
      "  3' UTR: 43104122-43104261\n",
      "  3' UTR: 43099775-43099880\n",
      "  3' UTR: 43097493-43097586\n",
      "  3' UTR: 43097244-43097289\n",
      "  3' UTR: 43095846-43095922\n",
      "  3' UTR: 43094033-43094860\n",
      "\n",
      "Transcript 35: ENST00000492859 \n",
      "Start: 43094112\n",
      "End: 43125300\n",
      "UTRs:\n",
      "  5' UTR: 43125271-43125300\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43110465-43110534\n",
      "  3' UTR: 43106456-43106533\n",
      "  3' UTR: 43104868-43104956\n",
      "  3' UTR: 43104122-43104261\n",
      "  3' UTR: 43099775-43099880\n",
      "  3' UTR: 43097244-43097289\n",
      "  3' UTR: 43095846-43095922\n",
      "  3' UTR: 43094112-43094860\n",
      "\n",
      "Transcript 36: ENST00000642945 \n",
      "Start: 43094482\n",
      "End: 43125343\n",
      "UTRs:\n",
      "  5' UTR: 43125277-43125343\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43112487-43112494\n",
      "  3' UTR: 43106456-43106533\n",
      "  3' UTR: 43104868-43104956\n",
      "  3' UTR: 43104122-43104261\n",
      "  3' UTR: 43099775-43099880\n",
      "  3' UTR: 43097244-43097289\n",
      "  3' UTR: 43095846-43095922\n",
      "  3' UTR: 43094482-43094860\n",
      "\n",
      "Transcript 37: ENST00000700184 \n",
      "Start: 43099643\n",
      "End: 43124339\n",
      "\n",
      "Transcript 38: ENST00000461798 \n",
      "Start: 43099831\n",
      "End: 43125370\n",
      "UTRs:\n",
      "  5' UTR: 43125277-43125370\n",
      "  5' UTR: 43124097-43124115\n",
      "  3' UTR: 43104868-43104954\n",
      "  3' UTR: 43104122-43104261\n",
      "  3' UTR: 43099831-43099880\n",
      "\n",
      "Transcript 39: ENST00000700083 \n",
      "Start: 43104225\n",
      "End: 43106139\n",
      "\n",
      "Transcript 40: ENST00000700185 \n",
      "Start: 43114391\n",
      "End: 43125370\n",
      "\n",
      "Transcript 41: ENST00000700186 \n",
      "Start: 43122343\n",
      "End: 43125370\n",
      "\n",
      "Promoter Sequence (first 100 bp):\n",
      "GCTGGATTATAGTGGCTTGATCTTGGCTCACTGCAGCCTCAACCTCCAGCACTCAAGCAATTCGCCCACCTCAACCTCCGGAGTAGCTGGAACCACAGGT...\n",
      "Exported Xpresso input data to xpresso_input.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "class GeneInfoRetriever:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://rest.ensembl.org\"\n",
    "        self.headers = {\"Content-Type\": \"application/json\"}\n",
    "        self.sleep_time = 0.5  # To respect Ensembl API rate limits\n",
    "\n",
    "    def get_gene_id(self, gene_symbol, species=\"human\"):\n",
    "        \"\"\"Retrieve the Ensembl gene ID for a gene symbol.\"\"\"\n",
    "        species_map = {\"human\": \"homo_sapiens\", \"mouse\": \"mus_musculus\"}\n",
    "        species_name = species_map.get(species.lower(), species)\n",
    "        \n",
    "        endpoint = f\"/lookup/symbol/{species_name}/{gene_symbol}\"\n",
    "        response = self._make_request(endpoint)\n",
    "        \n",
    "        if response:\n",
    "            return response.get(\"id\")\n",
    "        return None\n",
    "\n",
    "    def get_gene_sequence(self, gene_id):\n",
    "        \"\"\"Retrieve the gene sequence for a gene ID.\"\"\"\n",
    "        endpoint = f\"/sequence/id/{gene_id}?type=genomic\"\n",
    "        response = self._make_request(endpoint)\n",
    "        \n",
    "        if response:\n",
    "            return response.get(\"seq\")\n",
    "        return None\n",
    "        \n",
    "    def get_promoter_sequence(self, gene_id, upstream=7000, downstream=3500):\n",
    "        \"\"\"\n",
    "        Retrieve the promoter region sequence around the TSS.\n",
    "        Default: 7kb upstream to 3.5kb downstream of TSS (Xpresso default)\n",
    "        \n",
    "        Parameters:\n",
    "        gene_id (str): Ensembl gene ID\n",
    "        upstream (int): Number of bases upstream of TSS\n",
    "        downstream (int): Number of bases downstream of TSS\n",
    "        \n",
    "        Returns:\n",
    "        str: The promoter sequence\n",
    "        \"\"\"\n",
    "        # Get gene coordinates\n",
    "        coords = self.get_gene_coordinates(gene_id)\n",
    "        if not coords:\n",
    "            return None\n",
    "            \n",
    "        chromosome = coords[\"chromosome\"]\n",
    "        strand = coords[\"strand\"]\n",
    "        \n",
    "        # Calculate TSS position based on strand\n",
    "        tss_position = coords[\"start\"] if strand == 1 else coords[\"end\"]\n",
    "        \n",
    "        # Calculate region to fetch based on strand\n",
    "        if strand == 1:  # Forward strand\n",
    "            seq_start = tss_position - upstream\n",
    "            seq_end = tss_position + downstream\n",
    "        else:  # Reverse strand\n",
    "            seq_start = tss_position - downstream\n",
    "            seq_end = tss_position + upstream\n",
    "        \n",
    "        # Ensure coordinates are positive\n",
    "        seq_start = max(1, seq_start)\n",
    "        \n",
    "        # Get the sequence\n",
    "        strand_str = \"1\" if strand == 1 else \"-1\"\n",
    "        endpoint = f\"/sequence/region/human/{chromosome}:{seq_start}..{seq_end}:{strand_str}\"\n",
    "        response = self._make_request(endpoint)\n",
    "        \n",
    "        if response:\n",
    "            return response.get(\"seq\")\n",
    "        return None\n",
    "\n",
    "    def get_gene_coordinates(self, gene_id):\n",
    "        \"\"\"Retrieve the genomic coordinates for a gene ID.\"\"\"\n",
    "        endpoint = f\"/lookup/id/{gene_id}?expand=1\"\n",
    "        response = self._make_request(endpoint)\n",
    "        \n",
    "        if response:\n",
    "            return {\n",
    "                \"chromosome\": response.get(\"seq_region_name\"),\n",
    "                \"start\": response.get(\"start\"),\n",
    "                \"end\": response.get(\"end\"),\n",
    "                \"strand\": response.get(\"strand\")\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    def get_tss_location(self, gene_id):\n",
    "        \"\"\"\n",
    "        Retrieve the transcription start site (TSS) location.\n",
    "        The TSS is typically at the start of the gene on the positive strand,\n",
    "        or at the end of the gene on the negative strand.\n",
    "        \"\"\"\n",
    "        coords = self.get_gene_coordinates(gene_id)\n",
    "        \n",
    "        if coords:\n",
    "            # For genes on the positive strand, TSS is at the start\n",
    "            # For genes on the negative strand, TSS is at the end\n",
    "            tss = coords[\"start\"] if coords[\"strand\"] == 1 else coords[\"end\"]\n",
    "            return {\n",
    "                \"chromosome\": coords[\"chromosome\"],\n",
    "                \"position\": tss,\n",
    "                \"strand\": coords[\"strand\"]\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    def get_transcript_info(self, gene_id):\n",
    "        \"\"\"Get information about all transcripts for a gene, including UTRs.\"\"\"\n",
    "        # This endpoint needs to be expanded to include UTRs\n",
    "        endpoint = f\"/lookup/id/{gene_id}?expand=1&utr=1\"\n",
    "        response = self._make_request(endpoint)\n",
    "        \n",
    "        transcripts = []\n",
    "        if response and \"Transcript\" in response:\n",
    "            for transcript in response[\"Transcript\"]:\n",
    "                # Extract basic transcript information\n",
    "                transcript_info = {\n",
    "                    \"transcript_id\": transcript.get(\"id\"),\n",
    "                    \"start\": transcript.get(\"start\"),\n",
    "                    \"end\": transcript.get(\"end\"),\n",
    "                    \"strand\": transcript.get(\"strand\"),\n",
    "                    \"is_canonical\": transcript.get(\"is_canonical\", 0),\n",
    "                    \"biotype\": transcript.get(\"biotype\", \"\"),\n",
    "                    \"UTRs\": []\n",
    "                }\n",
    "                \n",
    "                # Extract UTR information based on actual Ensembl API response structure\n",
    "                if \"UTR\" in transcript:\n",
    "                    for utr in transcript[\"UTR\"]:\n",
    "                        utr_type = \"5' UTR\" if utr.get(\"object_type\") == \"five_prime_UTR\" else \"3' UTR\"\n",
    "                        transcript_info[\"UTRs\"].append({\n",
    "                            \"start\": utr.get(\"start\"),\n",
    "                            \"end\": utr.get(\"end\"),\n",
    "                            \"type\": utr_type\n",
    "                        })\n",
    "                \n",
    "                # Add exon information if present\n",
    "                if \"Exon\" in transcript:\n",
    "                    transcript_info[\"Exon\"] = transcript[\"Exon\"]\n",
    "                \n",
    "                transcripts.append(transcript_info)\n",
    "        \n",
    "        # Sort transcripts so canonical is first if present\n",
    "        transcripts.sort(key=lambda x: x[\"is_canonical\"], reverse=True)\n",
    "                \n",
    "        return transcripts\n",
    "        \n",
    "    def get_canonical_transcript(self, gene_id):\n",
    "        \"\"\"Get the canonical transcript for a gene.\"\"\"\n",
    "        transcripts = self.get_transcript_info(gene_id)\n",
    "        \n",
    "        # First try to find the transcript marked as canonical\n",
    "        for transcript in transcripts:\n",
    "            if transcript.get(\"is_canonical\") == 1:\n",
    "                return transcript\n",
    "                \n",
    "        # If no canonical transcript is marked, look for protein_coding transcripts\n",
    "        protein_coding = [t for t in transcripts if t.get(\"biotype\") == \"protein_coding\"]\n",
    "        if protein_coding:\n",
    "            return protein_coding[0]\n",
    "            \n",
    "        # If no protein coding transcripts, return the first one\n",
    "        return transcripts[0] if transcripts else None\n",
    "\n",
    "    def _make_request(self, endpoint):\n",
    "        \"\"\"Make a request to the Ensembl REST API.\"\"\"\n",
    "        url = self.base_url + endpoint\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            time.sleep(self.sleep_time)  # Be nice to the API\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                print(f\"Error: {response.status_code} - {response.text}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Request error: {e}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_sequence_features(self, sequence):\n",
    "        \"\"\"\n",
    "        Calculate sequence-derived features for Xpresso input.\n",
    "        \n",
    "        Parameters:\n",
    "        sequence (str): DNA sequence\n",
    "        \n",
    "        Returns:\n",
    "        dict: Dictionary of sequence features\n",
    "        \"\"\"\n",
    "        if not sequence:\n",
    "            return None\n",
    "            \n",
    "        # Calculate GC content\n",
    "        gc_count = sequence.upper().count('G') + sequence.upper().count('C')\n",
    "        gc_content = gc_count / len(sequence)\n",
    "        \n",
    "        return {\n",
    "            \"gc_content\": gc_content,\n",
    "            \"sequence_length\": len(sequence)\n",
    "        }\n",
    "    \n",
    "    def calculate_transcript_features(self, canonical_transcript):\n",
    "        \"\"\"\n",
    "        Calculate transcript-derived features for Xpresso input.\n",
    "        \n",
    "        Parameters:\n",
    "        canonical_transcript (dict): Canonical transcript information\n",
    "        \n",
    "        Returns:\n",
    "        dict: Dictionary of transcript features\n",
    "        \"\"\"\n",
    "        if not canonical_transcript:\n",
    "            return {\n",
    "                \"five_prime_utr_length\": 0,\n",
    "                \"three_prime_utr_length\": 0,\n",
    "                \"total_utr_length\": 0,\n",
    "                \"five_prime_utrs\": [],\n",
    "                \"three_prime_utrs\": [],\n",
    "                \"transcript_id\": None\n",
    "            }\n",
    "            \n",
    "        # Calculate UTR lengths\n",
    "        five_prime_utrs = [utr for utr in canonical_transcript[\"UTRs\"] if utr[\"type\"] == \"5' UTR\"]\n",
    "        three_prime_utrs = [utr for utr in canonical_transcript[\"UTRs\"] if utr[\"type\"] == \"3' UTR\"]\n",
    "        \n",
    "        five_prime_utr_length = sum(utr[\"end\"] - utr[\"start\"] + 1 for utr in five_prime_utrs) if five_prime_utrs else 0\n",
    "        three_prime_utr_length = sum(utr[\"end\"] - utr[\"start\"] + 1 for utr in three_prime_utrs) if three_prime_utrs else 0\n",
    "        \n",
    "        # Calculate exon junction density\n",
    "        exon_count = len(canonical_transcript.get(\"Exon\", []))\n",
    "        transcript_length = canonical_transcript[\"end\"] - canonical_transcript[\"start\"] + 1\n",
    "        exon_junction_density = (exon_count - 1) / transcript_length if exon_count > 1 and transcript_length > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"five_prime_utr_length\": five_prime_utr_length,\n",
    "            \"three_prime_utr_length\": three_prime_utr_length,\n",
    "            \"total_utr_length\": five_prime_utr_length + three_prime_utr_length,\n",
    "            \"five_prime_utrs\": five_prime_utrs,\n",
    "            \"three_prime_utrs\": three_prime_utrs,\n",
    "            \"transcript_id\": canonical_transcript.get(\"transcript_id\"),\n",
    "            \"exon_count\": exon_count,\n",
    "            \"transcript_length\": transcript_length,\n",
    "            \"exon_junction_density\": exon_junction_density\n",
    "        }\n",
    "    \n",
    "    def get_all_gene_info(self, gene_symbol, species=\"human\"):\n",
    "        \"\"\"Retrieve all information about a gene, including Xpresso features.\"\"\"\n",
    "        # Get the Ensembl gene ID\n",
    "        gene_id = self.get_gene_id(gene_symbol, species)\n",
    "        if not gene_id:\n",
    "            return {\"error\": f\"Gene {gene_symbol} not found\"}\n",
    "        \n",
    "        # Get the gene sequence\n",
    "        sequence = self.get_gene_sequence(gene_id)\n",
    "        \n",
    "        # Get the gene coordinates\n",
    "        coordinates = self.get_gene_coordinates(gene_id)\n",
    "        \n",
    "        # Get the TSS location\n",
    "        tss = self.get_tss_location(gene_id)\n",
    "        \n",
    "        # Get transcript information (including UTRs)\n",
    "        transcripts = self.get_transcript_info(gene_id)\n",
    "        \n",
    "        # Get the canonical transcript\n",
    "        canonical_transcript = self.get_canonical_transcript(gene_id)\n",
    "        \n",
    "        # Get the promoter sequence (7kb upstream to 3.5kb downstream of TSS)\n",
    "        promoter_sequence = self.get_promoter_sequence(gene_id)\n",
    "        \n",
    "        # Calculate sequence features\n",
    "        sequence_features = self.calculate_sequence_features(promoter_sequence)\n",
    "        \n",
    "        # Calculate transcript features from the canonical transcript\n",
    "        transcript_features = self.calculate_transcript_features(canonical_transcript)\n",
    "        \n",
    "        return {\n",
    "            \"gene_symbol\": gene_symbol,\n",
    "            \"gene_id\": gene_id,\n",
    "            \"sequence\": sequence,\n",
    "            \"promoter_sequence\": promoter_sequence,\n",
    "            \"coordinates\": coordinates,\n",
    "            \"tss\": tss,\n",
    "            \"transcripts\": transcripts,\n",
    "            \"canonical_transcript\": canonical_transcript,\n",
    "            \"sequence_features\": sequence_features,\n",
    "            \"transcript_features\": transcript_features\n",
    "        }\n",
    "\n",
    "def one_hot_encode_sequence(sequence):\n",
    "    \"\"\"\n",
    "    One-hot encode a DNA sequence.\n",
    "    \n",
    "    Parameters:\n",
    "    sequence (str): DNA sequence\n",
    "    \n",
    "    Returns:\n",
    "    list: One-hot encoded sequence (list of lists)\n",
    "    \"\"\"\n",
    "    # Define the mapping\n",
    "    mapping = {\n",
    "        'A': [1, 0, 0, 0],\n",
    "        'C': [0, 1, 0, 0],\n",
    "        'G': [0, 0, 1, 0],\n",
    "        'T': [0, 0, 0, 1],\n",
    "        'N': [0, 0, 0, 0]  # For unknown bases\n",
    "    }\n",
    "    \n",
    "    # Convert sequence to uppercase and one-hot encode\n",
    "    sequence = sequence.upper()\n",
    "    encoded = []\n",
    "    for base in sequence:\n",
    "        # Use N encoding for any non-standard bases\n",
    "        if base not in mapping:\n",
    "            base = 'N'\n",
    "        encoded.append(mapping[base])\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "def export_for_xpresso(gene_info, output_file=\"xpresso_input.npz\"):\n",
    "    \"\"\"\n",
    "    Export gene information in a format suitable for Xpresso.\n",
    "    \n",
    "    Parameters:\n",
    "    gene_info (dict): Gene information dictionary\n",
    "    output_file (str): Output filename\n",
    "    \n",
    "    Returns:\n",
    "    bool: Success status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract the promoter sequence\n",
    "        promoter_seq = gene_info[\"promoter_sequence\"]\n",
    "        if not promoter_seq:\n",
    "            print(\"Error: No promoter sequence available\")\n",
    "            return False\n",
    "        \n",
    "        # One-hot encode the sequence\n",
    "        one_hot_seq = one_hot_encode_sequence(promoter_seq)\n",
    "        \n",
    "        # Extract additional features from canonical transcript\n",
    "        five_prime_utr_length = gene_info[\"transcript_features\"][\"five_prime_utr_length\"]\n",
    "        three_prime_utr_length = gene_info[\"transcript_features\"][\"three_prime_utr_length\"]\n",
    "        gc_content = gene_info[\"sequence_features\"][\"gc_content\"]\n",
    "        exon_junction_density = gene_info[\"transcript_features\"][\"exon_junction_density\"]\n",
    "        \n",
    "        # Create a dictionary of features\n",
    "        features = {\n",
    "            \"one_hot_sequence\": one_hot_seq,\n",
    "            \"five_prime_utr_length\": five_prime_utr_length,\n",
    "            \"three_prime_utr_length\": three_prime_utr_length,\n",
    "            \"gc_content\": gc_content,\n",
    "            \"exon_junction_density\": exon_junction_density,\n",
    "            \"gene_id\": gene_info[\"gene_id\"],\n",
    "            \"gene_symbol\": gene_info[\"gene_symbol\"],\n",
    "            \"transcript_id\": gene_info[\"transcript_features\"][\"transcript_id\"],\n",
    "            \"tss_position\": gene_info[\"tss\"][\"position\"],\n",
    "            \"chromosome\": gene_info[\"tss\"][\"chromosome\"]\n",
    "        }\n",
    "        \n",
    "        # Save to file (using a simple JSON format for now)\n",
    "        import json\n",
    "        with open(output_file.replace(\".npz\", \".json\"), \"w\") as f:\n",
    "            # Convert numpy arrays to lists for JSON serialization\n",
    "            json_features = features.copy()\n",
    "            json_features[\"one_hot_sequence\"] = one_hot_seq\n",
    "            json.dump(json_features, f, indent=2)\n",
    "        \n",
    "        print(f\"Exported Xpresso input data to {output_file.replace('.npz', '.json')}\")\n",
    "        \n",
    "        # Note: For a real .npz file (numpy array format), you would use:\n",
    "        # import numpy as np\n",
    "        # np.savez(output_file, \n",
    "        #    one_hot_sequence=np.array(one_hot_seq),\n",
    "        #    five_prime_utr_length=five_prime_utr_length,\n",
    "        #    three_prime_utr_length=three_prime_utr_length,\n",
    "        #    gc_content=gc_content,\n",
    "        #    exon_junction_density=exon_junction_density)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting Xpresso input: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    # Predefined variables - change these values as needed\n",
    "    gene_symbol = \"BRCA1\"  # Example gene\n",
    "    species = \"human\"      # Default species\n",
    "    \n",
    "    retriever = GeneInfoRetriever()\n",
    "    result = retriever.get_all_gene_info(gene_symbol, species)\n",
    "    \n",
    "    # Print results\n",
    "    if \"error\" in result:\n",
    "        print(result[\"error\"])\n",
    "    else:\n",
    "        print(f\"Gene: {result['gene_symbol']} (Ensembl ID: {result['gene_id']})\")\n",
    "        print(\"\\nGenome Coordinates:\")\n",
    "        print(f\"Chromosome: {result['coordinates']['chromosome']}\")\n",
    "        print(f\"Start: {result['coordinates']['start']}\")\n",
    "        print(f\"End: {result['coordinates']['end']}\")\n",
    "        print(f\"Strand: {'+' if result['coordinates']['strand'] == 1 else '-'}\")\n",
    "        \n",
    "        print(\"\\nTranscription Start Site (TSS):\")\n",
    "        print(f\"Chromosome: {result['tss']['chromosome']}\")\n",
    "        print(f\"Position: {result['tss']['position']}\")\n",
    "        \n",
    "        print(\"\\nXpresso Input Features:\")\n",
    "        print(f\"Promoter sequence length: {len(result['promoter_sequence'])} bp\")\n",
    "        print(f\"GC content: {result['sequence_features']['gc_content']:.2f}\")\n",
    "        print(f\"5' UTR length: {result['transcript_features']['five_prime_utr_length']} bp\")\n",
    "        print(f\"3' UTR length: {result['transcript_features']['three_prime_utr_length']} bp\")\n",
    "        \n",
    "        print(\"\\nCanonical Transcript:\")\n",
    "        canonical = result['canonical_transcript']\n",
    "        if canonical:\n",
    "            print(f\"Transcript ID: {canonical['transcript_id']}\")\n",
    "            print(f\"Start: {canonical['start']}\")\n",
    "            print(f\"End: {canonical['end']}\")\n",
    "            print(f\"Is Canonical: {'Yes' if canonical.get('is_canonical') == 1 else 'No'}\")\n",
    "            \n",
    "            if canonical['UTRs']:\n",
    "                print(\"\\nCanonical UTRs:\")\n",
    "                for utr in canonical['UTRs']:\n",
    "                    print(f\"  {utr['type']}: {utr['start']}-{utr['end']} (length: {utr['end'] - utr['start'] + 1} bp)\")\n",
    "            \n",
    "            # Summary of UTR lengths\n",
    "            five_prime_length = result['transcript_features']['five_prime_utr_length']\n",
    "            three_prime_length = result['transcript_features']['three_prime_utr_length']\n",
    "            print(f\"\\nTotal 5' UTR length: {five_prime_length} bp\")\n",
    "            print(f\"Total 3' UTR length: {three_prime_length} bp\")\n",
    "            print(f\"Total UTR length: {five_prime_length + three_prime_length} bp\")\n",
    "            \n",
    "            # Show exon information\n",
    "            exon_count = result['transcript_features']['exon_count']\n",
    "            if exon_count > 0:\n",
    "                print(f\"\\nExon count: {exon_count}\")\n",
    "                print(f\"Exon junction density: {result['transcript_features']['exon_junction_density']:.6f}\")\n",
    "        \n",
    "        print(\"\\nAll Transcripts:\")\n",
    "        for i, transcript in enumerate(result['transcripts'], 1):\n",
    "            print(f\"\\nTranscript {i}: {transcript['transcript_id']} {'(CANONICAL)' if transcript.get('is_canonical') == 1 else ''}\")\n",
    "            print(f\"Start: {transcript['start']}\")\n",
    "            print(f\"End: {transcript['end']}\")\n",
    "            \n",
    "            if transcript['UTRs']:\n",
    "                print(\"UTRs:\")\n",
    "                for utr in transcript['UTRs']:\n",
    "                    print(f\"  {utr['type']}: {utr['start']}-{utr['end']}\")\n",
    "        \n",
    "        print(\"\\nPromoter Sequence (first 100 bp):\")\n",
    "        if result['promoter_sequence']:\n",
    "            print(result['promoter_sequence'][:100] + \"...\")\n",
    "            \n",
    "        # Export data for Xpresso\n",
    "        export_for_xpresso(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utrgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
